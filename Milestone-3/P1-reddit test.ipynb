{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BPoa3D7zcF1K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "piYLfO46jL2R"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbbzS_H2cF1T",
        "outputId": "0ca2eac4-242a-4ee2-aa6f-08c84e4e91b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# data_path = '/home/arsh/Jasleen/Spring 2023/NLP/Group Project/Authorship-Attribution-for-Neural-Text-Generation-master/data/'\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qk-SUeHMdFRp"
      },
      "outputs": [],
      "source": [
        "data_path = 'drive/MyDrive/NLP/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rTu7oIwWjdC2",
        "outputId": "01214b36-2046-43a3-fa51-1adf435431df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text        class\n",
              "11721  how much of your body is your own how much of ...  instructgpt\n",
              "11722  how do you keep a space station clean how do y...  instructgpt\n",
              "11723  the city where you pay a years rent up front t...  instructgpt\n",
              "11724  the bbc news app gives you the best of bbc new...  instructgpt\n",
              "11725  learn how the bbc is working to strengthen tru...  instructgpt"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98fc3c1a-d902-4fa2-9b3a-813c21296c2f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11721</th>\n",
              "      <td>how much of your body is your own how much of ...</td>\n",
              "      <td>instructgpt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11722</th>\n",
              "      <td>how do you keep a space station clean how do y...</td>\n",
              "      <td>instructgpt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11723</th>\n",
              "      <td>the city where you pay a years rent up front t...</td>\n",
              "      <td>instructgpt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11724</th>\n",
              "      <td>the bbc news app gives you the best of bbc new...</td>\n",
              "      <td>instructgpt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11725</th>\n",
              "      <td>learn how the bbc is working to strengthen tru...</td>\n",
              "      <td>instructgpt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98fc3c1a-d902-4fa2-9b3a-813c21296c2f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-98fc3c1a-d902-4fa2-9b3a-813c21296c2f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-98fc3c1a-d902-4fa2-9b3a-813c21296c2f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data = pd.read_csv(data_path + 'input.csv')\n",
        "data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAka2_HaAMeS",
        "outputId": "8b84029d-7901-49c0-8acf-f1c47d737160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "MxP-XGDKgClx",
        "outputId": "ed96a7d4-4f7b-4f63-996c-b468e57166da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 prompt1  \\\n",
              "0      news this parkville girl knows the lasting eff...   \n",
              "1      news an incredibly fast dark matter hurricane ...   \n",
              "2      news how ancient egyptian cosmetics influenced...   \n",
              "3      news 5minute hummus recipe n this is a simple ...   \n",
              "4      news bbc news n london  the british government...   \n",
              "...                                                  ...   \n",
              "10995  the mother and the murderer the mother and the...   \n",
              "10996  the fastest way to pay off 10000 in credit car...   \n",
              "10997  this parkville girl knows the lasting effects ...   \n",
              "10998  how do you keep a space station clean how do y...   \n",
              "10999  science  environment science  environment appl...   \n",
              "\n",
              "                                                 prompt2  class  \n",
              "0      news learning to live with the coronavirus n t...      0  \n",
              "1      news flu shot theres a mismatch this season  a...      0  \n",
              "2      news the queen is making her most serious miss...      0  \n",
              "3      news the clanwilliam cedar survived the last i...      0  \n",
              "4      news preserving macaos handmade signs in the d...      0  \n",
              "...                                                  ...    ...  \n",
              "10995  south africans in wuhan lockdown call for evac...      0  \n",
              "10996  gloria gaynor fights coronavirus by taking her...      1  \n",
              "10997  with coronavirus its time to declare a nationa...      0  \n",
              "10998  china cosmetic surgery apps swipe to buy a new...      1  \n",
              "10999  together we make a family together we make a f...      0  \n",
              "\n",
              "[11000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e21aaa6c-6ba9-466e-a10a-44ef6073c216\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt1</th>\n",
              "      <th>prompt2</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>news this parkville girl knows the lasting eff...</td>\n",
              "      <td>news learning to live with the coronavirus n t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>news an incredibly fast dark matter hurricane ...</td>\n",
              "      <td>news flu shot theres a mismatch this season  a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>news how ancient egyptian cosmetics influenced...</td>\n",
              "      <td>news the queen is making her most serious miss...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>news 5minute hummus recipe n this is a simple ...</td>\n",
              "      <td>news the clanwilliam cedar survived the last i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>news bbc news n london  the british government...</td>\n",
              "      <td>news preserving macaos handmade signs in the d...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10995</th>\n",
              "      <td>the mother and the murderer the mother and the...</td>\n",
              "      <td>south africans in wuhan lockdown call for evac...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10996</th>\n",
              "      <td>the fastest way to pay off 10000 in credit car...</td>\n",
              "      <td>gloria gaynor fights coronavirus by taking her...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10997</th>\n",
              "      <td>this parkville girl knows the lasting effects ...</td>\n",
              "      <td>with coronavirus its time to declare a nationa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10998</th>\n",
              "      <td>how do you keep a space station clean how do y...</td>\n",
              "      <td>china cosmetic surgery apps swipe to buy a new...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10999</th>\n",
              "      <td>science  environment science  environment appl...</td>\n",
              "      <td>together we make a family together we make a f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e21aaa6c-6ba9-466e-a10a-44ef6073c216')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e21aaa6c-6ba9-466e-a10a-44ef6073c216 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e21aaa6c-6ba9-466e-a10a-44ef6073c216');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Creating new pairs\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the data from the CSV file\n",
        "# df = pd.read_csv('input.csv')\n",
        "df=data\n",
        "\n",
        "# Select only 100 samples from each class\n",
        "grouped = df.groupby('class').apply(lambda x: x.sample(n=min(len(x), 1000))).reset_index(drop=True)\n",
        "\n",
        "# Group the selected data by the \"class\" column\n",
        "grouped = grouped.groupby('class')\n",
        "\n",
        "# Randomly select 10 rows from each group\n",
        "samples = []\n",
        "for _, group in grouped:\n",
        "    samples.extend(list(zip(group.sample(n=1000, replace=True).index, \n",
        "                             group.sample(n=1000, replace=True).index)))\n",
        "\n",
        "\n",
        "# Generate pairs from the selected rows and random rows from other classes\n",
        "pairs = []\n",
        "labels = []\n",
        "for i, j in samples:\n",
        "    # Positive pair\n",
        "    if df['class'][i] == df['class'][j]:\n",
        "        pairs.append([df['text'][i], df['text'][j]])\n",
        "        labels.append(0)\n",
        "\n",
        "    # Negative pair\n",
        "    else:\n",
        "        while True:\n",
        "            k = np.random.choice(df.index)\n",
        "            if df['class'][k] != df['class'][i]:\n",
        "                pairs.append([df['text'][i], df['text'][k]])\n",
        "                labels.append(1)\n",
        "                break\n",
        "\n",
        "# Create a new dataframe with the pairs and labels\n",
        "new_df = pd.DataFrame({'prompt1': [p[0] for p in pairs], \n",
        "                       'prompt2': [p[1] for p in pairs], \n",
        "                       'class': labels})\n",
        "\n",
        "# Save the new dataframe to a CSV file\n",
        "new_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN3bI2SFp6Ib",
        "outputId": "88b8c2c4-0928-4826-aefb-148545817928"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    7143\n",
            "1    3857\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "counts = new_df['class'].value_counts()\n",
        "print(counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heN9DDKQt2lK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "Oianz98pt2dd",
        "outputId": "49059a38-9e3a-41d2-8194-c3148371aadd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-37-5867e0a4db03>:33: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  tokenizer.fit_on_texts(X_train['prompt1'].append(X_train['prompt2']))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "138/138 [==============================] - 126s 874ms/step - loss: 0.6845 - accuracy: 0.6464 - val_loss: 0.6758 - val_accuracy: 0.6559\n",
            "Epoch 2/10\n",
            "138/138 [==============================] - 119s 861ms/step - loss: 0.6711 - accuracy: 0.6465 - val_loss: 0.6636 - val_accuracy: 0.6568\n",
            "Epoch 3/10\n",
            "138/138 [==============================] - 117s 846ms/step - loss: 0.6624 - accuracy: 0.6465 - val_loss: 0.6561 - val_accuracy: 0.6559\n",
            "Epoch 4/10\n",
            "138/138 [==============================] - 119s 864ms/step - loss: 0.6569 - accuracy: 0.6465 - val_loss: 0.6512 - val_accuracy: 0.6559\n",
            "Epoch 5/10\n",
            "138/138 [==============================] - 116s 838ms/step - loss: 0.6536 - accuracy: 0.6465 - val_loss: 0.6481 - val_accuracy: 0.6559\n",
            "Epoch 6/10\n",
            "138/138 [==============================] - 115s 832ms/step - loss: 0.6517 - accuracy: 0.6465 - val_loss: 0.6462 - val_accuracy: 0.6559\n",
            "Epoch 7/10\n",
            " 74/138 [===============>..............] - ETA: 47s - loss: 0.6484 - accuracy: 0.6512"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-5867e0a4db03>\u001b[0m in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq1_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# evaluate the model's performance on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Siamese with lstm\n",
        "\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "# from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Lambda\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "\n",
        "df_sampled=new_df\n",
        "\n",
        "# extract the prompts and labels\n",
        "prompts = df_sampled[['prompt1', 'prompt2']]\n",
        "labels = df_sampled['class']\n",
        "\n",
        "# split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(prompts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# create a tokenizer and fit it on the prompts\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train['prompt1'].append(X_train['prompt2']))\n",
        "\n",
        "# convert the prompts to sequences\n",
        "seq1_train = tokenizer.texts_to_sequences(X_train['prompt1'])\n",
        "seq2_train = tokenizer.texts_to_sequences(X_train['prompt2'])\n",
        "seq1_test = tokenizer.texts_to_sequences(X_test['prompt1'])\n",
        "seq2_test = tokenizer.texts_to_sequences(X_test['prompt2'])\n",
        "\n",
        "# pad the sequences\n",
        "max_length = max(max(len(x) for x in seq1_train), max(len(x) for x in seq2_train))\n",
        "seq1_train = pad_sequences(seq1_train, maxlen=max_length, padding='post')\n",
        "seq2_train = pad_sequences(seq2_train, maxlen=max_length, padding='post')\n",
        "seq1_test = pad_sequences(seq1_test, maxlen=max_length, padding='post')\n",
        "seq2_test = pad_sequences(seq2_test, maxlen=max_length, padding='post')\n",
        "\n",
        "# set the embedding dimension\n",
        "embedding_dim = 100\n",
        "\n",
        "# define the shared encoder\n",
        "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=max_length)\n",
        "lstm_layer = LSTM(units=50)\n",
        "\n",
        "# define the Siamese network\n",
        "input1 = Input(shape=(max_length,))\n",
        "input2 = Input(shape=(max_length,))\n",
        "embedded1 = embedding_layer(input1)\n",
        "embedded2 = embedding_layer(input2)\n",
        "encoded1 = lstm_layer(embedded1)\n",
        "encoded2 = lstm_layer(embedded2)\n",
        "merged = Lambda(lambda x: K.abs(x[0] - x[1]))([encoded1, encoded2])\n",
        "output = Dense(units=1, activation='sigmoid')(merged)\n",
        "model = Model(inputs=[input1, input2], outputs=output)\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "model.fit(x=[seq1_train, seq2_train], y=y_train, batch_size=64, epochs=10, validation_data=([seq1_test, seq2_test], y_test))\n",
        "\n",
        "# evaluate the model's performance on the test set\n",
        "accuracy = model.evaluate(x=[seq1_test, seq2_test], y=y_test)[1]\n",
        "print(f'Test accuracy: {accuracy:.3f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Wa1B1gXiALKj",
        "outputId": "48d194ed-db9e-4e89-cced-fbccd7149133"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-55d5de90-2709-4d0a-bdd7-0a121fd96e6a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt1</th>\n",
              "      <th>prompt2</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>news why britains hated pacer trains just wont...</td>\n",
              "      <td>news most states make it difficult for childre...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>news nathaniel hendren says katlyn alix knew r...</td>\n",
              "      <td>news the tourism legacy of the olympic games i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>news trump stumbles in first efforts to contro...</td>\n",
              "      <td>news delta announces its biggest flight capaci...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>news megan rapinoe slams us soccer for blatant...</td>\n",
              "      <td>news explore disneys new star wars land in 360...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>news fractured america got together on this is...</td>\n",
              "      <td>news the naked truth is that the united states...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10995</th>\n",
              "      <td>three british asian trailblazers you need to k...</td>\n",
              "      <td>trumps speech wont erase his bumbling response...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10996</th>\n",
              "      <td>were not talking to our girls enough about mon...</td>\n",
              "      <td>all aboard indias joyful toy train style 11 an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10997</th>\n",
              "      <td>business is booming for local woman making mas...</td>\n",
              "      <td>the story behind vietnams crazy house the stor...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10998</th>\n",
              "      <td>alabama town mirrors us class divide on immigr...</td>\n",
              "      <td>opinion  we need to flatten the curve trump an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10999</th>\n",
              "      <td>coronavirus updates borders shut as coronaviru...</td>\n",
              "      <td>the mystery of the missing bus riders the myst...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55d5de90-2709-4d0a-bdd7-0a121fd96e6a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55d5de90-2709-4d0a-bdd7-0a121fd96e6a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55d5de90-2709-4d0a-bdd7-0a121fd96e6a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 prompt1  \\\n",
              "0      news why britains hated pacer trains just wont...   \n",
              "1      news nathaniel hendren says katlyn alix knew r...   \n",
              "2      news trump stumbles in first efforts to contro...   \n",
              "3      news megan rapinoe slams us soccer for blatant...   \n",
              "4      news fractured america got together on this is...   \n",
              "...                                                  ...   \n",
              "10995  three british asian trailblazers you need to k...   \n",
              "10996  were not talking to our girls enough about mon...   \n",
              "10997  business is booming for local woman making mas...   \n",
              "10998  alabama town mirrors us class divide on immigr...   \n",
              "10999  coronavirus updates borders shut as coronaviru...   \n",
              "\n",
              "                                                 prompt2  class  \n",
              "0      news most states make it difficult for childre...      0  \n",
              "1      news the tourism legacy of the olympic games i...      0  \n",
              "2      news delta announces its biggest flight capaci...      0  \n",
              "3      news explore disneys new star wars land in 360...      0  \n",
              "4      news the naked truth is that the united states...      0  \n",
              "...                                                  ...    ...  \n",
              "10995  trumps speech wont erase his bumbling response...      1  \n",
              "10996  all aboard indias joyful toy train style 11 an...      1  \n",
              "10997  the story behind vietnams crazy house the stor...      1  \n",
              "10998  opinion  we need to flatten the curve trump an...      1  \n",
              "10999  the mystery of the missing bus riders the myst...      0  \n",
              "\n",
              "[11000 rows x 3 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k5yrEFI9bFp",
        "outputId": "d6fd9eed-f86b-47a6-bf35-a92cd614f617"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "69/69 [==============================] - 39s 443ms/step - loss: 0.6141 - accuracy: 0.6574 - val_loss: 0.6122 - val_accuracy: 0.6705\n",
            "Epoch 2/10\n",
            "69/69 [==============================] - 18s 257ms/step - loss: 0.5125 - accuracy: 0.7326 - val_loss: 0.5663 - val_accuracy: 0.6818\n",
            "Epoch 3/10\n",
            "69/69 [==============================] - 15s 216ms/step - loss: 0.3409 - accuracy: 0.8502 - val_loss: 0.6654 - val_accuracy: 0.6741\n",
            "Epoch 4/10\n",
            "69/69 [==============================] - 14s 207ms/step - loss: 0.1830 - accuracy: 0.9277 - val_loss: 0.8831 - val_accuracy: 0.6845\n",
            "Epoch 5/10\n",
            "69/69 [==============================] - 10s 142ms/step - loss: 0.1137 - accuracy: 0.9590 - val_loss: 1.0744 - val_accuracy: 0.7055\n",
            "Epoch 6/10\n",
            "69/69 [==============================] - 12s 170ms/step - loss: 0.0728 - accuracy: 0.9747 - val_loss: 1.3814 - val_accuracy: 0.6927\n",
            "Epoch 7/10\n",
            "69/69 [==============================] - 13s 194ms/step - loss: 0.0421 - accuracy: 0.9837 - val_loss: 1.8479 - val_accuracy: 0.6727\n",
            "Epoch 8/10\n",
            "69/69 [==============================] - 11s 157ms/step - loss: 0.0325 - accuracy: 0.9891 - val_loss: 1.7767 - val_accuracy: 0.6964\n",
            "Epoch 9/10\n",
            "69/69 [==============================] - 9s 130ms/step - loss: 0.0282 - accuracy: 0.9915 - val_loss: 1.8890 - val_accuracy: 0.6905\n",
            "Epoch 10/10\n",
            "69/69 [==============================] - 11s 157ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 2.1802 - val_accuracy: 0.7045\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5fed0f30d0>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Siamese with bilstm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load data into a pandas dataframe\n",
        "# data = pd.read_csv('data.csv')\n",
        "data=new_df\n",
        "\n",
        "\n",
        "# Split into training and testing sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize the prompts\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_data['prompt1'] + train_data['prompt2'])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Convert the prompts to sequences of tokens\n",
        "train_seqs1 = tokenizer.texts_to_sequences(train_data['prompt1'])\n",
        "train_seqs2 = tokenizer.texts_to_sequences(train_data['prompt2'])\n",
        "test_seqs1 = tokenizer.texts_to_sequences(test_data['prompt1'])\n",
        "test_seqs2 = tokenizer.texts_to_sequences(test_data['prompt2'])\n",
        "\n",
        "# Pad the sequences to the same length\n",
        "max_length = 200\n",
        "train_seqs1 = pad_sequences(train_seqs1, maxlen=max_length, padding='post', truncating='post')\n",
        "train_seqs2 = pad_sequences(train_seqs2, maxlen=max_length, padding='post', truncating='post')\n",
        "test_seqs1 = pad_sequences(test_seqs1, maxlen=max_length, padding='post', truncating='post')\n",
        "test_seqs2 = pad_sequences(test_seqs2, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "# Define the Siamese neural network architecture with BiLSTM\n",
        "embedding_dim = 128\n",
        "lstm_dim = 64\n",
        "\n",
        "input_1 = layers.Input(shape=(max_length,))\n",
        "input_2 = layers.Input(shape=(max_length,))\n",
        "\n",
        "embedding_layer = layers.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "lstm_layer = layers.Bidirectional(layers.LSTM(lstm_dim))\n",
        "\n",
        "encoded1 = lstm_layer(embedding_layer(input_1))\n",
        "encoded2 = lstm_layer(embedding_layer(input_2))\n",
        "\n",
        "merged = layers.concatenate([encoded1, encoded2], axis=-1)\n",
        "merged = layers.Dense(32, activation='relu')(merged)\n",
        "merged = layers.Dropout(0.2)(merged)\n",
        "output = layers.Dense(1, activation='sigmoid')(merged)\n",
        "\n",
        "siamese_model = models.Model(inputs=[input_1, input_2], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = optimizers.Adam(learning_rate=0.01)\n",
        "siamese_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "batch_size = 128\n",
        "\n",
        "siamese_model.fit([train_seqs1, train_seqs2], train_data['class'],\n",
        "                  epochs=epochs,\n",
        "                  batch_size=batch_size,\n",
        "                  validation_data=([test_seqs1, test_seqs2], test_data['class']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81P0Phc8GTJ_",
        "outputId": "01d31c1b-c03e-4e5d-ba4c-0fd272471beb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "69/69 [==============================] - 42s 401ms/step - loss: 0.5694 - accuracy: 0.6964 - val_loss: 0.4641 - val_accuracy: 0.7923\n",
            "Epoch 2/10\n",
            "69/69 [==============================] - 20s 291ms/step - loss: 0.4188 - accuracy: 0.8131 - val_loss: 0.4119 - val_accuracy: 0.8068\n",
            "Epoch 3/10\n",
            "69/69 [==============================] - 21s 292ms/step - loss: 0.3375 - accuracy: 0.8436 - val_loss: 0.4249 - val_accuracy: 0.8073\n",
            "Epoch 4/10\n",
            "69/69 [==============================] - 16s 231ms/step - loss: 0.2586 - accuracy: 0.8838 - val_loss: 0.4885 - val_accuracy: 0.8000\n",
            "Epoch 5/10\n",
            "69/69 [==============================] - 16s 240ms/step - loss: 0.1740 - accuracy: 0.9269 - val_loss: 0.6036 - val_accuracy: 0.7786\n",
            "Epoch 6/10\n",
            "69/69 [==============================] - 14s 203ms/step - loss: 0.1182 - accuracy: 0.9506 - val_loss: 0.7226 - val_accuracy: 0.7600\n",
            "Epoch 7/10\n",
            "69/69 [==============================] - 11s 167ms/step - loss: 0.0814 - accuracy: 0.9694 - val_loss: 1.1055 - val_accuracy: 0.7705\n",
            "Epoch 8/10\n",
            "69/69 [==============================] - 15s 219ms/step - loss: 0.0589 - accuracy: 0.9767 - val_loss: 1.2045 - val_accuracy: 0.7682\n",
            "Epoch 9/10\n",
            "69/69 [==============================] - 11s 160ms/step - loss: 0.0470 - accuracy: 0.9818 - val_loss: 1.2206 - val_accuracy: 0.7673\n",
            "Epoch 10/10\n",
            "69/69 [==============================] - 12s 171ms/step - loss: 0.0436 - accuracy: 0.9839 - val_loss: 1.2797 - val_accuracy: 0.7645\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd0ec0aac20>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Siamese with word2vec\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load data into a pandas dataframe\n",
        "data=new_df\n",
        "\n",
        "# Split into training and testing sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize the prompts\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_data['prompt1'] + train_data['prompt2'])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Convert the prompts to sequences of tokens\n",
        "train_seqs1 = tokenizer.texts_to_sequences(train_data['prompt1'])\n",
        "train_seqs2 = tokenizer.texts_to_sequences(train_data['prompt2'])\n",
        "test_seqs1 = tokenizer.texts_to_sequences(test_data['prompt1'])\n",
        "test_seqs2 = tokenizer.texts_to_sequences(test_data['prompt2'])\n",
        "\n",
        "# Pad the sequences to the same length\n",
        "max_length = 200\n",
        "train_seqs1 = pad_sequences(train_seqs1, maxlen=max_length, padding='post', truncating='post')\n",
        "train_seqs2 = pad_sequences(train_seqs2, maxlen=max_length, padding='post', truncating='post')\n",
        "test_seqs1 = pad_sequences(test_seqs1, maxlen=max_length, padding='post', truncating='post')\n",
        "test_seqs2 = pad_sequences(test_seqs2, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "# Train Word2Vec model on the corpus\n",
        "sentences = [sentence.split() for sentence in train_data['prompt1'] + train_data['prompt2']]\n",
        "word2vec_model = Word2Vec(sentences, vector_size=128, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Create embedding matrix for the tokenizer vocabulary\n",
        "embedding_dim = 128\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in word2vec_model.wv:\n",
        "        embedding_matrix[i] = word2vec_model.wv[word]\n",
        "\n",
        "# Define the Siamese neural network architecture with BiLSTM\n",
        "lstm_dim = 64\n",
        "\n",
        "input_1 = layers.Input(shape=(max_length,))\n",
        "input_2 = layers.Input(shape=(max_length,))\n",
        "\n",
        "embedding_layer = layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix])\n",
        "\n",
        "lstm_layer = layers.Bidirectional(layers.LSTM(lstm_dim))\n",
        "\n",
        "encoded1 = lstm_layer(embedding_layer(input_1))\n",
        "encoded2 = lstm_layer(embedding_layer(input_2))\n",
        "\n",
        "merged = layers.concatenate([encoded1, encoded2], axis=-1)\n",
        "merged = layers.Dense(32, activation='relu')(merged)\n",
        "merged = layers.Dropout(0.2)(merged)\n",
        "output = layers.Dense(1, activation='sigmoid')(merged)\n",
        "\n",
        "siamese_model = models.Model(inputs=[input_1, input_2], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = optimizers.Adam(learning_rate=0.01)\n",
        "siamese_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "siamese_model.fit([train_seqs1, train_seqs2], train_data['class'],\n",
        "                  epochs=epochs,\n",
        "                  batch_size=batch_size,\n",
        "                  validation_data=([test_seqs1, test_seqs2], test_data['class']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rkfhAucQw-O",
        "outputId": "7e336263-ae3e-4a8f-dd8c-b9e0b8aeebb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 1s 21ms/step - loss: 1.2797 - accuracy: 0.7645\n",
            "Test loss: 1.2797282934188843\n",
            "Test accuracy: 0.7645454406738281\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = siamese_model.evaluate([test_seqs1, test_seqs2], test_data['class'])\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-taXcUsQ01I",
        "outputId": "cf14a3d2-a82c-413a-ddec-5c04f8db7516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 3s 17ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.81      0.83      0.82      1435\n",
            "     class 1       0.67      0.63      0.65       765\n",
            "\n",
            "    accuracy                           0.76      2200\n",
            "   macro avg       0.74      0.73      0.74      2200\n",
            "weighted avg       0.76      0.76      0.76      2200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = siamese_model.predict([test_seqs1, test_seqs2])\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Generate classification report\n",
        "target_names = ['class 0', 'class 1']\n",
        "print(classification_report(test_data['class'], y_pred, target_names=target_names))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9UwGTicKMR3e"
      },
      "outputs": [],
      "source": [
        "def predict_same(prompt1, prompt2):\n",
        "    # Preprocess input prompts using the same tokenizer used during training\n",
        "    prompt1_seq = tokenizer.texts_to_sequences([prompt1])[0]\n",
        "    prompt2_seq = tokenizer.texts_to_sequences([prompt2])[0]\n",
        "    prompt1_padded = pad_sequences([prompt1_seq], maxlen=max_length, padding='post', truncating='post')\n",
        "    prompt2_padded = pad_sequences([prompt2_seq], maxlen=max_length, padding='post', truncating='post')\n",
        "    \n",
        "    # Predict using the trained model\n",
        "    prediction = siamese_model.predict([prompt1_padded, prompt2_padded])[0][0]\n",
        "    \n",
        "    # Return True if prediction is above a threshold, False otherwise\n",
        "    threshold = 0.5\n",
        "    return prediction < threshold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5TuHsLgMRoS",
        "outputId": "6ead1fa1-f7e4-4c37-a5ec-c1a4381ce596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt1acdc guitarist malcolm young dies at 64  blasted and bleeding everywhere dead bodies dying body sover again  news reports today america celebrates freedom day as well  applause continues on stage outside capitol building washington dc usa president bill clinton remarks here is one more thing about democracy tomorrow world leaders meeting tonight worldwide peace talks begin monday noon sharp global summit wednesday afternoon session of the council security committee thursday evening special sessions assembly members meetings weekly attendance rate increases daily increase rates monthly changes yearly change annual adjustment annually adjusted periodically adjusting regularly changing frequencies frequency decreases percentage rises percent falls percentages rise  fall proportion decline ratio drops ratios drop proportions decrease numbers rising or falling amounts increasing levels decreasing quantities declining prices dropping values lowering costs raising them all simultaneously simultaneous events occur globally televised live from london bbc two three four five six seven eight nine ten eleven twelve thirteen fourteen fifteen sixteen seventeen eighteen nineteen twenty twentyone twentytwo twentythree twentyfour twentyfive twentysix thirty thirty34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 103 104 105 107 108 109 110 111 112 113 now 1983 inflation 3 1 purchasing international station 1982 descending 2 twentydoubling reducing raises 6 4 sum 5 33 ascending nato selling 0 7 18 9 hiring week distributing distribution dividing 8 quantity production downward limiting budget 11 o rescheduling 220 c manufacturing calendar reduction amount 00 10 crow13 12 0exchange adding 1984 01 19 16 development 14 downbalancing down 17 tuesday charging a s what in me x b n suncapital i 3triby sunset   raise consuming lifting par r diamond gold t to 4adexpress essence level d new plus  oh job double joy pyramid  with coffee carbon apple currency twins super midnight  bond blacknight rare bar patch emotion exclow coin diamonds mass grinbonus rain black add bullcross  clarity extra up iron platinum po mountain color dry sspeed ee eye root apple death go infinity tree excess shift self earth elemental car atom shine exotic weight prime nut element experience atmosphere planet dumbvalence fairy p aurora ore animal ball strength ground atoms point onion de gross el rich rite you metal hair y co moon extinction plant\n",
            "prompt2endoftextgloria gaynor fights coronavirus by taking her hit song i will survive to the sinkthe singers album my beautiful dark twisted fantasy is due for release next monthher song is a love song written for a love interestgloria gaynor is a catchy and catchy love song that will have everyone singing its praises as soon as its released on the album my beautiful dark twisted fantasya song that is a love song to the singer of hit singles like im a celebrity and has a hit song by another of the stars favourite singers christina aguilera has been a hit since its release on june 30the song is a simple love song written with no wordsgloria gaynor the singer has taken it upon herself to fight the coronavirus epidemic by releasing my beautiful dark twisted fantasy on june 30glorias hit song i will survive is written as a love song for the love interest who has taken her lifeshe wrote it for a man who is currently being treated in hospital for his condition caused by his condition being caused by the virusgaynors song has been taken by the publics heart by taking a hit to the head in an attempt to save the mans life the song has been covered by lady gaga lady gaga of course but the singer herself has also made the song a hit in her own waygaynors album my beautiful dark twisted fantasy is due for release next month on july 21i will survive the song is a simple love song that has been taken a hit to the head to save the mans lifea fan wrote gaynor and asked her to write the song and the singer responded saying that she will take her hit song to her fans to the tune of a hit it was also reported on the website that gaynor has been receiving treatment for a heart conditiona spokesperson from the singer responded saying the song is written with a message to my fans and is a love and hope song to the man in hospitalthe man has died of an acute conditionthis was a personal matter for the manwe all are grieving and are heartbrokenour hearts go out to the family and those that were touched by the songendoftextthe latest in our monthly roundup with the most interesting news coming in on\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Both generated by different method\n"
          ]
        }
      ],
      "source": [
        "prompt1 = input(\"prompt1\")\n",
        "prompt2 = input(\"prompt2\")\n",
        "same_or_not = predict_same(prompt1, prompt2)\n",
        "if same_or_not:\n",
        "  print(\"Both generated by same method\")  # Output: True\n",
        "else:\n",
        "  print(\"Both generated by different method\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_model.save(data_path+'siamese_model.h5')\n"
      ],
      "metadata": {
        "id": "7kOKhEy_cJMt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating new pairs\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the data from the CSV file\n",
        "df = pd.read_csv(data_path +'reddit_input.csv')\n",
        "\n",
        "# Select only 500 samples from each class\n",
        "grouped = df.groupby('class').apply(lambda x: x.sample(n=min(len(x), 500))).reset_index(drop=True)\n",
        "\n",
        "# Group the selected data by the \"class\" column\n",
        "grouped = grouped.groupby('class')\n",
        "\n",
        "# Randomly select 500 rows from each group\n",
        "samples = []\n",
        "for _, group in grouped:\n",
        "    samples.extend(list(zip(group.sample(n=500, replace=True).index, \n",
        "                             group.sample(n=500, replace=True).index)))\n",
        "\n",
        "\n",
        "# Generate pairs from the selected rows and random rows from other classes\n",
        "pairs = []\n",
        "labels = []\n",
        "for i, j in samples:\n",
        "    # Positive pair\n",
        "    if df['class'][i] == df['class'][j]:\n",
        "        pairs.append([df['text'][i], df['text'][j]])\n",
        "        labels.append(0)\n",
        "\n",
        "    # Negative pair\n",
        "    else:\n",
        "        while True:\n",
        "            k = np.random.choice(df.index)\n",
        "            if df['class'][k] != df['class'][i]:\n",
        "                pairs.append([df['text'][i], df['text'][k]])\n",
        "                labels.append(1)\n",
        "                break\n",
        "\n",
        "# Create a new dataframe with the pairs and labels\n",
        "new_df_reddit = pd.DataFrame({'prompt1': [p[0] for p in pairs], \n",
        "                       'prompt2': [p[1] for p in pairs], \n",
        "                       'class': labels})\n",
        "\n",
        "# Save the new dataframe to a CSV file\n",
        "new_df_reddit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9LwaTnfBcIxv",
        "outputId": "4138c94d-4d9c-4fa2-b8c3-f18300811a92"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                prompt1  \\\n",
              "0     do i give my addict mum a chance or am i only ...   \n",
              "1     cheesecake is actually pie not cakeits pi day ...   \n",
              "2     update on my parents stealing my medsthank you...   \n",
              "3     gpt4 is the most intelligent entity in the kno...   \n",
              "4     most pollution enthusiasts cant logically reas...   \n",
              "...                                                 ...   \n",
              "1495  people who post videosphotos of themselves doi...   \n",
              "1496  depositors at svb took a risk and lost its not...   \n",
              "1497  forgiving my 23f mom 54f for what she didi for...   \n",
              "1498  me 18f about to get ghosted by 18mhey 18m  i h...   \n",
              "1499  does having mental health issues make someone ...   \n",
              "\n",
              "                                                prompt2  class  \n",
              "0     fiancmy fianc wanted to go out to the club wit...      0  \n",
              "1     27f 31m how do i approach this topic of differ...      0  \n",
              "2     fianc 35m has recently been telling me 25f tha...      0  \n",
              "3     splitting bills with my30m relativeshousemates...      0  \n",
              "4     the people of the united states have the right...      0  \n",
              "...                                                 ...    ...  \n",
              "1495  people are just generally too stupid to have a...      1  \n",
              "1496  im worried by boyfriend finds me too clingyif ...      1  \n",
              "1497  there is no reason to assume animals cant expe...      0  \n",
              "1498  parental advicemy mom and dad arent in love an...      1  \n",
              "1499  friend goes on long monologues and doesnt want...      0  \n",
              "\n",
              "[1500 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-beb6d94d-549d-4a5a-89ea-ac627e483204\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt1</th>\n",
              "      <th>prompt2</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>do i give my addict mum a chance or am i only ...</td>\n",
              "      <td>fiancmy fianc wanted to go out to the club wit...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cheesecake is actually pie not cakeits pi day ...</td>\n",
              "      <td>27f 31m how do i approach this topic of differ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>update on my parents stealing my medsthank you...</td>\n",
              "      <td>fianc 35m has recently been telling me 25f tha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gpt4 is the most intelligent entity in the kno...</td>\n",
              "      <td>splitting bills with my30m relativeshousemates...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>most pollution enthusiasts cant logically reas...</td>\n",
              "      <td>the people of the united states have the right...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>people who post videosphotos of themselves doi...</td>\n",
              "      <td>people are just generally too stupid to have a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>depositors at svb took a risk and lost its not...</td>\n",
              "      <td>im worried by boyfriend finds me too clingyif ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>forgiving my 23f mom 54f for what she didi for...</td>\n",
              "      <td>there is no reason to assume animals cant expe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>me 18f about to get ghosted by 18mhey 18m  i h...</td>\n",
              "      <td>parental advicemy mom and dad arent in love an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>does having mental health issues make someone ...</td>\n",
              "      <td>friend goes on long monologues and doesnt want...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-beb6d94d-549d-4a5a-89ea-ac627e483204')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-beb6d94d-549d-4a5a-89ea-ac627e483204 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-beb6d94d-549d-4a5a-89ea-ac627e483204');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = new_df_reddit['class'].value_counts()\n",
        "print(counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTw6tSWwd6f0",
        "outputId": "415949bf-0b47-4171-b68b-59745940cfc1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    1090\n",
            "1     410\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Reddit data as test data for already trained model\n",
        "\n",
        "# Load data into a pandas dataframe\n",
        "test_data=new_df_reddit\n",
        "\n",
        "# Tokenize the prompts\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(test_data['prompt1'] + test_data['prompt2'])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Convert the prompts to sequences of tokens\n",
        "test_seqs1 = tokenizer.texts_to_sequences(test_data['prompt1'])\n",
        "test_seqs2 = tokenizer.texts_to_sequences(test_data['prompt2'])\n",
        "\n",
        "# Pad the sequences to the same length\n",
        "max_length = 200\n",
        "test_seqs1 = pad_sequences(test_seqs1, maxlen=max_length, padding='post', truncating='post')\n",
        "test_seqs2 = pad_sequences(test_seqs2, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = siamese_model.predict([test_seqs1, test_seqs2])\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Generate classification report\n",
        "target_names = ['class 0', 'class 1']\n",
        "print(classification_report(test_data['class'], y_pred, target_names=target_names))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMsqpuggeJ6l",
        "outputId": "6857e0f1-7952-4479-f67d-e9bc28d26d92"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 1s 15ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.72      0.67      0.69      1090\n",
            "     class 1       0.26      0.30      0.28       410\n",
            "\n",
            "    accuracy                           0.57      1500\n",
            "   macro avg       0.49      0.49      0.49      1500\n",
            "weighted avg       0.59      0.57      0.58      1500\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}