{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BPoa3D7zcF1K"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "piYLfO46jL2R"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PbbzS_H2cF1T",
    "outputId": "6af11f5f-442f-4f48-f130-463b33a88c91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# # data_path = '/home/arsh/Jasleen/Spring 2023/NLP/Group Project/Authorship-Attribution-for-Neural-Text-Generation-master/data/'\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qk-SUeHMdFRp"
   },
   "outputs": [],
   "source": [
    "data_path = 'drive/MyDrive/NLP/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rTu7oIwWjdC2"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path+'input.csv')\n",
    "# data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "9Oznd2V6XdVF",
    "outputId": "afbb5ec8-db67-40c0-d98a-04624f5046f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-95ca7232-f0b0-4c97-8edc-b9921beeb5de\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt1</th>\n",
       "      <th>prompt2</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news ncaas decision to cancel the big dance is...</td>\n",
       "      <td>news legendary chef michel roux dies aged 78 n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news apple says its fine to wipe your iphone w...</td>\n",
       "      <td>news together we make a family of four n i hav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news locked up and learning to write women pri...</td>\n",
       "      <td>news step into the world of americas most noto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news opinion  a story from inside the coronavi...</td>\n",
       "      <td>news they plan to march for gender equality in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news roast chicken in a butter crust recipe n ...</td>\n",
       "      <td>news vaping whats a parent to do n the answer ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>new packaging and plantbased fish how bumble b...</td>\n",
       "      <td>local news in and as long until it is that too...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>nikki haley an unprecedented step on human rig...</td>\n",
       "      <td>canada faces danger from china and russia inte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>without god life is still meaningful opinion w...</td>\n",
       "      <td>how do you beat highflying liverpool watfords ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>makoko nigerias floating slum goes digital mak...</td>\n",
       "      <td>is it allergies the flu or the coronavirus how...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>where trump support and obamacare use soar whe...</td>\n",
       "      <td>endoftexthe quit his highpaying job to build b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows Ã— 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95ca7232-f0b0-4c97-8edc-b9921beeb5de')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-95ca7232-f0b0-4c97-8edc-b9921beeb5de button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-95ca7232-f0b0-4c97-8edc-b9921beeb5de');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                 prompt1  \\\n",
       "0      news ncaas decision to cancel the big dance is...   \n",
       "1      news apple says its fine to wipe your iphone w...   \n",
       "2      news locked up and learning to write women pri...   \n",
       "3      news opinion  a story from inside the coronavi...   \n",
       "4      news roast chicken in a butter crust recipe n ...   \n",
       "...                                                  ...   \n",
       "10995  new packaging and plantbased fish how bumble b...   \n",
       "10996  nikki haley an unprecedented step on human rig...   \n",
       "10997  without god life is still meaningful opinion w...   \n",
       "10998  makoko nigerias floating slum goes digital mak...   \n",
       "10999  where trump support and obamacare use soar whe...   \n",
       "\n",
       "                                                 prompt2  class  \n",
       "0      news legendary chef michel roux dies aged 78 n...      0  \n",
       "1      news together we make a family of four n i hav...      0  \n",
       "2      news step into the world of americas most noto...      0  \n",
       "3      news they plan to march for gender equality in...      0  \n",
       "4      news vaping whats a parent to do n the answer ...      0  \n",
       "...                                                  ...    ...  \n",
       "10995  local news in and as long until it is that too...      1  \n",
       "10996  canada faces danger from china and russia inte...      0  \n",
       "10997  how do you beat highflying liverpool watfords ...      1  \n",
       "10998  is it allergies the flu or the coronavirus how...      0  \n",
       "10999  endoftexthe quit his highpaying job to build b...      1  \n",
       "\n",
       "[11000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating new pairs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data from the CSV file\n",
    "# df = pd.read_csv('input.csv')\n",
    "df=data\n",
    "\n",
    "# Select only 100 samples from each class\n",
    "grouped = df.groupby('class').apply(lambda x: x.sample(n=min(len(x), 1000))).reset_index(drop=True)\n",
    "\n",
    "# Group the selected data by the \"class\" column\n",
    "grouped = grouped.groupby('class')\n",
    "\n",
    "# Randomly select 10 rows from each group\n",
    "samples = []\n",
    "for _, group in grouped:\n",
    "    samples.extend(list(zip(group.sample(n=1000, replace=True).index, \n",
    "                             group.sample(n=1000, replace=True).index)))\n",
    "\n",
    "\n",
    "# Generate pairs from the selected rows and random rows from other classes\n",
    "pairs = []\n",
    "labels = []\n",
    "for i, j in samples:\n",
    "    # Positive pair\n",
    "    if df['class'][i] == df['class'][j]:\n",
    "        pairs.append([df['text'][i], df['text'][j]])\n",
    "        labels.append(0)\n",
    "\n",
    "    # Negative pair\n",
    "    else:\n",
    "        while True:\n",
    "            k = np.random.choice(df.index)\n",
    "            if df['class'][k] != df['class'][i]:\n",
    "                pairs.append([df['text'][i], df['text'][k]])\n",
    "                labels.append(1)\n",
    "                break\n",
    "\n",
    "# Create a new dataframe with the pairs and labels\n",
    "new_df = pd.DataFrame({'prompt1': [p[0] for p in pairs], \n",
    "                       'prompt2': [p[1] for p in pairs], \n",
    "                       'class': labels})\n",
    "\n",
    "# Save the new dataframe to a CSV file\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0-tkoAaDh2k"
   },
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6USkPxctU2a4",
    "outputId": "fb871230-e749-4607-f59e-366fb698deeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 4s 29ms/step - loss: 0.7655 - accuracy: 0.5000 - val_loss: 0.6942 - val_accuracy: 0.5175\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.7611 - accuracy: 0.4819 - val_loss: 0.6908 - val_accuracy: 0.5475\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.7239 - accuracy: 0.5312 - val_loss: 0.6910 - val_accuracy: 0.5300\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.7372 - accuracy: 0.4869 - val_loss: 0.6911 - val_accuracy: 0.4975\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.7176 - accuracy: 0.5156 - val_loss: 0.6879 - val_accuracy: 0.5525\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.7118 - accuracy: 0.5300 - val_loss: 0.6883 - val_accuracy: 0.5475\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.7267 - accuracy: 0.4944 - val_loss: 0.6878 - val_accuracy: 0.5525\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.7060 - accuracy: 0.5100 - val_loss: 0.6852 - val_accuracy: 0.5575\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.6976 - accuracy: 0.5150 - val_loss: 0.6881 - val_accuracy: 0.5575\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.6983 - accuracy: 0.5275 - val_loss: 0.6859 - val_accuracy: 0.5550\n",
      "Test loss: 0.6858899593353271\n",
      "Test accuracy: 0.5550000071525574\n"
     ]
    }
   ],
   "source": [
    "# Simple Neural Model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "# Read in the dataset\n",
    "df = new_df\n",
    "\n",
    "# Split the dataset into samples with label 0 and 1\n",
    "label_0_df = df[df['class'] == 0].sample(n=1000, random_state=42)\n",
    "label_1_df = df[df['class'] == 1].sample(n=1000, random_state=42)\n",
    "\n",
    "# Combine the two samples\n",
    "sample_df = pd.concat([label_0_df, label_1_df])\n",
    "\n",
    "# Convert the text prompts to numerical features using Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sample_df[['prompt1', 'prompt2']].apply(lambda x: ' '.join(x), axis=1))\n",
    "X = tokenizer.texts_to_sequences(sample_df[['prompt1', 'prompt2']].apply(lambda x: ' '.join(x), axis=1))\n",
    "\n",
    "# Pad the sequences to a fixed length\n",
    "max_length = 300\n",
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "# Add a third dimension to X\n",
    "X = np.expand_dims(X, axis=2)\n",
    "\n",
    "# Convert the labels to be in the range [0, 1]\n",
    "y = sample_df['class'].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(max_length, 1)),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]}')\n",
    "print(f'Test accuracy: {score[1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_9-fWqODkGl"
   },
   "source": [
    "BidirectionalLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pizMks9uqniN",
    "outputId": "32b83c7c-e8ad-4719-b02a-48dc65511ec9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 72s 1s/step - loss: 0.6861 - accuracy: 0.5794 - val_loss: 0.6655 - val_accuracy: 0.5975\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 67s 1s/step - loss: 0.4987 - accuracy: 0.7850 - val_loss: 0.5688 - val_accuracy: 0.6900\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 67s 1s/step - loss: 0.1741 - accuracy: 0.9531 - val_loss: 0.6945 - val_accuracy: 0.7125\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 66s 1s/step - loss: 0.0838 - accuracy: 0.9775 - val_loss: 0.7819 - val_accuracy: 0.7225\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 65s 1s/step - loss: 0.0810 - accuracy: 0.9775 - val_loss: 0.8981 - val_accuracy: 0.6975\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 63s 1s/step - loss: 0.0580 - accuracy: 0.9812 - val_loss: 0.9787 - val_accuracy: 0.7025\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 63s 1s/step - loss: 0.0492 - accuracy: 0.9819 - val_loss: 0.8835 - val_accuracy: 0.7450\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 63s 1s/step - loss: 0.0419 - accuracy: 0.9787 - val_loss: 0.9760 - val_accuracy: 0.7150\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 63s 1s/step - loss: 0.0386 - accuracy: 0.9844 - val_loss: 0.8986 - val_accuracy: 0.7200\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 62s 1s/step - loss: 0.0388 - accuracy: 0.9837 - val_loss: 1.1058 - val_accuracy: 0.7200\n",
      "Test loss: 1.1058363914489746\n",
      "Test accuracy: 0.7200000286102295\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional, Embedding, SpatialDropout1D\n",
    "\n",
    "# Read in the dataset\n",
    "# df = pd.read_csv('p1_dataset.csv')\n",
    "df = new_df\n",
    "\n",
    "# # Split the dataset into samples with label 0 and 1\n",
    "# label_0_df = df[df['class'] == 0].sample(n=10000, random_state=42)\n",
    "# label_1_df = df[df['class'] == 1].sample(n=10000, random_state=42)\n",
    "\n",
    "# Sample from each label, reducing the requested size if necessary\n",
    "sample_size = 10000\n",
    "if len(label_0_df) < sample_size:\n",
    "    sample_size = len(label_0_df)\n",
    "if len(label_1_df) < sample_size:\n",
    "    sample_size = len(label_1_df)\n",
    "\n",
    "label_0_df = label_0_df.sample(n=sample_size, random_state=42, replace=True)\n",
    "label_1_df = label_1_df.sample(n=sample_size, random_state=42, replace=True)\n",
    "\n",
    "# Combine the two samples\n",
    "sample_df = pd.concat([label_0_df, label_1_df])\n",
    "\n",
    "# Convert the text prompts to numerical features using Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sample_df[['prompt1', 'prompt2']].apply(lambda x: ' '.join(x), axis=1))\n",
    "X = tokenizer.texts_to_sequences(sample_df[['prompt1', 'prompt2']].apply(lambda x: ' '.join(x), axis=1))\n",
    "\n",
    "# Pad the sequences to a fixed length\n",
    "max_length = 300\n",
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "# Add a third dimension to X\n",
    "X = np.expand_dims(X, axis=2)\n",
    "\n",
    "# Convert the labels to be in the range [0, 1]\n",
    "y = sample_df['class'].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Embedding(len(tokenizer.word_index) + 1, 128, input_length=max_length),\n",
    "    SpatialDropout1D(0.2),\n",
    "    Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]}')\n",
    "print(f'Test accuracy: {score[1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfcDHn97Do1Y"
   },
   "source": [
    "BI-LSTm with L2 Regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "giHiLqwfCDqj",
    "outputId": "ce121ed8-9e6b-48ca-ca2e-ab67965804fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "275/275 [==============================] - 365s 1s/step - loss: 0.6475 - accuracy: 0.6390 - val_loss: 0.6234 - val_accuracy: 0.6427\n",
      "Epoch 2/10\n",
      "275/275 [==============================] - 345s 1s/step - loss: 0.5399 - accuracy: 0.7323 - val_loss: 0.6581 - val_accuracy: 0.6123\n",
      "Epoch 3/10\n",
      "275/275 [==============================] - 336s 1s/step - loss: 0.4157 - accuracy: 0.8190 - val_loss: 0.7540 - val_accuracy: 0.6105\n",
      "Epoch 4/10\n",
      "275/275 [==============================] - 323s 1s/step - loss: 0.3390 - accuracy: 0.8608 - val_loss: 0.7864 - val_accuracy: 0.6182\n",
      "Epoch 5/10\n",
      "275/275 [==============================] - 325s 1s/step - loss: 0.2965 - accuracy: 0.8760 - val_loss: 0.9000 - val_accuracy: 0.6073\n",
      "Epoch 6/10\n",
      "275/275 [==============================] - 314s 1s/step - loss: 0.2694 - accuracy: 0.8799 - val_loss: 0.9213 - val_accuracy: 0.6068\n",
      "Epoch 7/10\n",
      "275/275 [==============================] - 323s 1s/step - loss: 0.2507 - accuracy: 0.8865 - val_loss: 0.8804 - val_accuracy: 0.6259\n",
      "Epoch 8/10\n",
      "275/275 [==============================] - 321s 1s/step - loss: 0.2355 - accuracy: 0.8864 - val_loss: 0.9726 - val_accuracy: 0.6009\n",
      "Epoch 9/10\n",
      "275/275 [==============================] - 322s 1s/step - loss: 0.2201 - accuracy: 0.8897 - val_loss: 1.0690 - val_accuracy: 0.5950\n",
      "Epoch 10/10\n",
      "275/275 [==============================] - 320s 1s/step - loss: 0.2119 - accuracy: 0.8889 - val_loss: 1.0637 - val_accuracy: 0.5991\n",
      "Test loss: 1.0636736154556274\n",
      "Test accuracy: 0.5990909337997437\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional, Embedding, SpatialDropout1D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Read in the dataset\n",
    "sample_df=new_df\n",
    "\n",
    "# Convert the text prompts to numerical features using Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sample_df[['prompt1', 'prompt2']].apply(lambda x: ' '.join(x), axis=1))\n",
    "X = tokenizer.texts_to_sequences(sample_df[['prompt1', 'prompt2']].apply(lambda x: ' '.join(x), axis=1))\n",
    "\n",
    "# Pad the sequences to a fixed length\n",
    "max_length = 300\n",
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "# Add a third dimension to X\n",
    "X = np.expand_dims(X, axis=2)\n",
    "\n",
    "# Convert the labels to be in the range [0, 1]\n",
    "y = sample_df['class'].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Embedding(len(tokenizer.word_index) + 1, 128, input_length=max_length),\n",
    "    SpatialDropout1D(0.2),\n",
    "    Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]}')\n",
    "print(f'Test accuracy: {score[1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrfCda0DNfPM"
   },
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3FHfgPbTNiUX",
    "outputId": "2ea8060a-3919-461c-a700-e9a216fed0c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Read in the dataset\n",
    "# df = pd.read_csv('p1_dataset.csv')\n",
    "df = new_df\n",
    "\n",
    "# Sample from each label, reducing the requested size if necessary\n",
    "sample_size = 10000\n",
    "if len(label_0_df) < sample_size:\n",
    "    sample_size = len(label_0_df)\n",
    "if len(label_1_df) < sample_size:\n",
    "    sample_size = len(label_1_df)\n",
    "\n",
    "label_0_df = label_0_df.sample(n=sample_size, random_state=42, replace=True)\n",
    "label_1_df = label_1_df.sample(n=sample_size, random_state=42, replace=True)\n",
    "\n",
    "\n",
    "# Combine the two samples\n",
    "sample_df = pd.concat([label_0_df, label_1_df])\n",
    "\n",
    "# Convert the text prompts to a bag-of-words representation\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(sample_df[['prompt1', 'prompt2']].apply(lambda x: ' '.join(x), axis=1))\n",
    "\n",
    "# Convert the labels to be in the range [0, 1]\n",
    "y = sample_df['class'].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model architecture\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "score = model.score(X_test, y_test)\n",
    "print(f'Test accuracy: {score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGJTcZJJOghy"
   },
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T5RaXCp6OuqH",
    "outputId": "5a642b06-2c9f-4fc9-ff67-b0949884035b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Read in the dataset\n",
    "# df = pd.read_csv('p1_dataset.csv')\n",
    "df = new_df\n",
    "\n",
    "# Sample from each label, reducing the requested size if necessary\n",
    "sample_size = 10000\n",
    "if len(label_0_df) < sample_size:\n",
    "    sample_size = len(label_0_df)\n",
    "if len(label_1_df) < sample_size:\n",
    "    sample_size = len(label_1_df)\n",
    "\n",
    "label_0_df = label_0_df.sample(n=sample_size, random_state=42, replace=True)\n",
    "label_1_df = label_1_df.sample(n=sample_size, random_state=42, replace=True)\n",
    "\n",
    "\n",
    "# Combine the two samples\n",
    "sample_df = pd.concat([label_0_df, label_1_df])\n",
    "\n",
    "# Convert the text prompts to a bag-of-words representation\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(sample_df[['prompt1', 'prompt2']].apply(lambda x: ' '.join(x), axis=1))\n",
    "\n",
    "# Convert the labels to be in the range [0, 1]\n",
    "y = sample_df['class'].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model architecture\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "score = model.score(X_test, y_test)\n",
    "print(f'Test accuracy: {score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J1ZIXANxPLTO"
   },
   "outputs": [],
   "source": [
    "# Use the trained model to classify new prompt pairs\n",
    "def classify_prompt_pair(prompt1, prompt2, model, vectorizer):\n",
    "    prompt = vectorizer.transform([' '.join([prompt1, prompt2])])\n",
    "    y_pred = model.predict(prompt)[0]\n",
    "    if y_pred == 0:\n",
    "        return 'generated by the same method'\n",
    "    else:\n",
    "        return 'generated by different methods'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRXkuu0IPsba"
   },
   "outputs": [],
   "source": [
    "prompt1 = \"she makes sure unwanted food gets to hungry americans cnn  the online tipping scheme employing the people to ask guests to pay would go a long way to help make everyday objects more accessible to the hungry american people according to a new study from the foodgift club at mercy college in louisville kentuckynconsumers surveyed by the organization food for those in need indicated that most the supporters recognized that a person has food in his or her pocket when they ask guests who pay a tip the only way possible according to the reportnfiftyseven percent of those surveyed 55 million people agreed that theres an urgent need for a communitywide initiative to assist millions of americans who do not have enough to eat in these hungry homesnthe survey was conducted in march by the food for those in need organization based at the university of louisvillenfood for those in need officials said in a statement that the organization plans to partner with the nonprofit organization to find a way to help poor americansnthe hungry citizens  the most in need of hunger assistance nationwide said evans follin who oversees the organizations marketing and distribution we know that americans are fed up and hunger is one of the top priorities for the federal government millions of americans are facing a minimum budget shortfall as a result of the current economic crisis with food insecurity mounting and the number of americans still unable to purchase basic goods such as small essentials such as milk eggs and produce risingnin the department of agricultures rural development and production program more than onethird of the population or an estimated 14 million people are food insecure or at least have insufficient enough to eat according to the reportnconsumers who talk about hunger around food and benefits themselves are more likely to identify the opportunity as food from a local deli a convenience store or the butcher shop according to the food for those in need reportnconsumers who recommend someone to donate food to the hungry through a friend or family member indicated they feel empowered to make the need a priority when ordering food those food donations usually include coupons or tokens they would like to pass along to others who receive them the report saidnhumanity may look to and accept a few givers as part of an effort to provide additional food to a large number of the hungry americans at our very own a communitys number one cause of hunger the study saidnother positive charitable behaviors for individuals and families need to be emphasized in this group and that is why the food for those in need initiative focuses on finding partnersn\"\n",
    "prompt2 = \"how budapest became a fine dining force to be reckoned with and you were the one who made it happen because of which was your special role in that regard why for what reason  why noteopeod i have heard all about this movie but never actually seen any footage from its production so as far we are concerned there is no evidence whatsoever on our part regarding anything being done by any other person or entity at least none directly connected within hungary nor outside thereof such people would certainly need to know more concerning their own activities if they really wanted us involved either here inside hungarian territory elsewhere than where now exist some sorta network involving various individuals both locally along side national level even further out into the international arena perhaps including foreign governments like those currently in power over iran syria libya egypt iraq afghanistan pakistan yemen somalia sudan tanzania kenya uganda rwanda burundi zaire etc whatever these people might want them to do then again after realizing how much damage has been caused already through just doing nothing could possibly justify continuing without action against anyone else yet another example thus far only one though many others may well arise later upon the realizations shown me throughout my life however until next time letll keep things simple enough between ourselves rather than making too complicated an issue since most likely nobody will care anyway regardless whether something happens otherwise besides myself personally when eventually everything comes together before everyone can finally see themselves clearly hence also the point behind keeping matters simple while still remaining open up instead having someone try hard trying to make sure everybody knows exactly whose fault each individual situation truly lies under whom ever heshe believes should take responsibility therefore giving away very little information beyond simply stating oneself responsible plus pointing fingers towards whoever does wrong once somebody realized himself first hand quite often times becomes impossible due mostly owing mainly down to the fact every situation changes considerably depending entirely solely based off personal opinion versus objective truth despite knowing better yourself right around today maybe tomorrow sometime soon thereafter although neither one shall always be true nonetheless whenever situations change sometimes difficult decisions must inevitably come forth especially considering certain factors given above namely the following ones first thing foremost please remember beforehand everyone doesnt deserve happiness except yourselveseop how did anybody get involved during filming itself unless specifically asked earlier according back home somewhere near budapest apparently few people seem to understand precisely how anyone got involved anywhere close sufficient quantity nevertheless thanks per usual wherever possible toward getting started properly beginning tonight hopefully shortly afterwards yes sir thankyou indeed yeah sir thanks thanks mister yes thank you mr thank you miss sorry miss sorry miss oh sorry miss oh sorry miss o sorry miss o too late miss late miss d dear d dear\"\n",
    "classification = classify_prompt_pair(prompt1, prompt2, model, vectorizer)\n",
    "print(f'{classification}.')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
