{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b07b9d9a55de4849b6a28e2a8ff9db24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e83776b5bd945a491fb172aaac558e9",
              "IPY_MODEL_4bceadfdc16048efb8138b04e4a1858b",
              "IPY_MODEL_a3742fc30b644da98ed6a6cf31905364"
            ],
            "layout": "IPY_MODEL_e737a1b4f48b492eba7f2470820320c3"
          }
        },
        "6e83776b5bd945a491fb172aaac558e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60d53d91d4d642fcb398f9c374ec013f",
            "placeholder": "​",
            "style": "IPY_MODEL_05cec9a212e54b92b31a59ea1aeff578",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "4bceadfdc16048efb8138b04e4a1858b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3d10ae1ff3b46ada4323b1ae0607724",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3034d189146d4b789d0ba197a31ed27c",
            "value": 570
          }
        },
        "a3742fc30b644da98ed6a6cf31905364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d377c0922d54f648fbcdbd763350fd7",
            "placeholder": "​",
            "style": "IPY_MODEL_6a4d1d0711384b959730636cf7a96f82",
            "value": " 570/570 [00:00&lt;00:00, 31.2kB/s]"
          }
        },
        "e737a1b4f48b492eba7f2470820320c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60d53d91d4d642fcb398f9c374ec013f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05cec9a212e54b92b31a59ea1aeff578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3d10ae1ff3b46ada4323b1ae0607724": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3034d189146d4b789d0ba197a31ed27c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d377c0922d54f648fbcdbd763350fd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a4d1d0711384b959730636cf7a96f82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10ce79e2ca364b16b66b70aca21bbfc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63da92c42c804caca16b3bc480e36bea",
              "IPY_MODEL_699dba8853fd479aa7dec4ceb70b6784",
              "IPY_MODEL_6ef7ae566bcb409eb1c155e8c48f24f0"
            ],
            "layout": "IPY_MODEL_ef7aabffb6b04b28995dd43db1427831"
          }
        },
        "63da92c42c804caca16b3bc480e36bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8ee40ace7fc44268ec5d986e29e9db6",
            "placeholder": "​",
            "style": "IPY_MODEL_44b770c00a8a44cd803980da739b901f",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "699dba8853fd479aa7dec4ceb70b6784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_057d5011807c4aa7bdf7a390a66df0c0",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a388d9a931e149cfadbd2e1c5bc0e443",
            "value": 440473133
          }
        },
        "6ef7ae566bcb409eb1c155e8c48f24f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5388041b53344320abe7e5f491371bd3",
            "placeholder": "​",
            "style": "IPY_MODEL_554dd9d8690c4b4280271ff18f34823c",
            "value": " 440M/440M [00:02&lt;00:00, 213MB/s]"
          }
        },
        "ef7aabffb6b04b28995dd43db1427831": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8ee40ace7fc44268ec5d986e29e9db6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44b770c00a8a44cd803980da739b901f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "057d5011807c4aa7bdf7a390a66df0c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a388d9a931e149cfadbd2e1c5bc0e443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5388041b53344320abe7e5f491371bd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "554dd9d8690c4b4280271ff18f34823c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53aa383cf8db48bc97e74aec9c607c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3f01db7ba8548b78fb45ad797e9612c",
              "IPY_MODEL_b2a636768d734ad6a1274a0d1e49e85d",
              "IPY_MODEL_8b19af34be654df8850182ed8b04fdc4"
            ],
            "layout": "IPY_MODEL_7cca5644df984e1bbfbd4a0a0d262969"
          }
        },
        "e3f01db7ba8548b78fb45ad797e9612c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_401a1d0bf006467e8bf8312e109f0c99",
            "placeholder": "​",
            "style": "IPY_MODEL_c5db9aba1a7a4e9dad524d84d441a037",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "b2a636768d734ad6a1274a0d1e49e85d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_028185ac864e48fe8e3533d192de6a8a",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98f17c9f55ce47498af41bb76fac5bf7",
            "value": 231508
          }
        },
        "8b19af34be654df8850182ed8b04fdc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4fdd3a05f494ccab577fdef43dfe575",
            "placeholder": "​",
            "style": "IPY_MODEL_92b30e4acad644c18dedf72c81c02433",
            "value": " 232k/232k [00:00&lt;00:00, 4.10MB/s]"
          }
        },
        "7cca5644df984e1bbfbd4a0a0d262969": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "401a1d0bf006467e8bf8312e109f0c99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5db9aba1a7a4e9dad524d84d441a037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "028185ac864e48fe8e3533d192de6a8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98f17c9f55ce47498af41bb76fac5bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4fdd3a05f494ccab577fdef43dfe575": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92b30e4acad644c18dedf72c81c02433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8109dbf0509043569d62981056ad1b73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b01b7887bb947bbafae1b0e4b8c82fc",
              "IPY_MODEL_81bfd750561644a8a2d4b1070d06b8f5",
              "IPY_MODEL_d8edcdfed1f84292a7edf8525b93393d"
            ],
            "layout": "IPY_MODEL_68b305a4266348e6addab1b46185d544"
          }
        },
        "3b01b7887bb947bbafae1b0e4b8c82fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12ec51c3c28d47acbfef91a8bdf95bd1",
            "placeholder": "​",
            "style": "IPY_MODEL_5e488d402c00450ab955e409b6c1c17d",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "81bfd750561644a8a2d4b1070d06b8f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02ea831e850f408fb83a3cb88f01fbdd",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbaa6b6b8ff14c0aabe19bfa617b2476",
            "value": 28
          }
        },
        "d8edcdfed1f84292a7edf8525b93393d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf7e8e0cacd249a682db1873045ef591",
            "placeholder": "​",
            "style": "IPY_MODEL_2d5fd2e989554673a85ade78b7b5aa99",
            "value": " 28.0/28.0 [00:00&lt;00:00, 407B/s]"
          }
        },
        "68b305a4266348e6addab1b46185d544": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12ec51c3c28d47acbfef91a8bdf95bd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e488d402c00450ab955e409b6c1c17d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02ea831e850f408fb83a3cb88f01fbdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbaa6b6b8ff14c0aabe19bfa617b2476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf7e8e0cacd249a682db1873045ef591": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d5fd2e989554673a85ade78b7b5aa99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "J4-CeLMqHh3v"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import pandas as pd\n",
        "combined_df=pd.read_csv(\"input-2.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Ca3JNGQHIOSo",
        "outputId": "3f6be06e-6c63-49d7-8f6e-ea4b9614e8a3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text        class\n",
              "0      news latest headlines on cnn business n tldr t...         ctrl\n",
              "1      news china wants to take a victory lap over it...         ctrl\n",
              "2      news coronavirus disinformation creates challe...         ctrl\n",
              "3      news china coronavirus eating wild animals mad...         ctrl\n",
              "4      news chinas economy could shrink for the first...         ctrl\n",
              "...                                                  ...          ...\n",
              "11721  how much of your body is your own how much of ...  instructgpt\n",
              "11722  how do you keep a space station clean how do y...  instructgpt\n",
              "11723  the city where you pay a years rent up front t...  instructgpt\n",
              "11724  the bbc news app gives you the best of bbc new...  instructgpt\n",
              "11725  learn how the bbc is working to strengthen tru...  instructgpt\n",
              "\n",
              "[11726 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-902e88a6-29e0-4c15-9b67-9b742ab5fd5e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>news latest headlines on cnn business n tldr t...</td>\n",
              "      <td>ctrl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>news china wants to take a victory lap over it...</td>\n",
              "      <td>ctrl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>news coronavirus disinformation creates challe...</td>\n",
              "      <td>ctrl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>news china coronavirus eating wild animals mad...</td>\n",
              "      <td>ctrl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>news chinas economy could shrink for the first...</td>\n",
              "      <td>ctrl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11721</th>\n",
              "      <td>how much of your body is your own how much of ...</td>\n",
              "      <td>instructgpt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11722</th>\n",
              "      <td>how do you keep a space station clean how do y...</td>\n",
              "      <td>instructgpt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11723</th>\n",
              "      <td>the city where you pay a years rent up front t...</td>\n",
              "      <td>instructgpt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11724</th>\n",
              "      <td>the bbc news app gives you the best of bbc new...</td>\n",
              "      <td>instructgpt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11725</th>\n",
              "      <td>learn how the bbc is working to strengthen tru...</td>\n",
              "      <td>instructgpt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11726 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-902e88a6-29e0-4c15-9b67-9b742ab5fd5e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-902e88a6-29e0-4c15-9b67-9b742ab5fd5e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-902e88a6-29e0-4c15-9b67-9b742ab5fd5e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "human_data = combined_df[combined_df['class'] == 'human']\n",
        "\n",
        "\n",
        "classes = ['ctrl', 'fair', 'gpt', 'gpt2', 'gpt3', 'grover', 'instructgpt', 'pplm', 'xlm', 'xlnet']\n",
        "\n",
        "\n",
        "class_dataframes = []\n",
        "for class_name in classes:\n",
        "    class_data = combined_df[combined_df['class'] == class_name]\n",
        "    class_dataframe = pd.concat([human_data, class_data]).reset_index(drop=True)\n",
        "    class_dataframes.append(class_dataframe)\n",
        "\n",
        "for i, class_name in enumerate(classes):\n",
        "    print(f\"Data frame for class {class_name}:\")\n",
        "    print(class_dataframes[i])\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igYUH-6uIkE8",
        "outputId": "4914bca1-e6f7-484e-c8b9-d462854cd970"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data frame for class ctrl:\n",
            "                                                   text  class\n",
            "0     latest headlines on cnn business latest headli...  human\n",
            "1     china wants to take a victory lap over its han...  human\n",
            "2     coronavirus disinformation creates challenges ...  human\n",
            "3     china coronavirus eating wild animals made ill...  human\n",
            "4     chinas economy could shrink for the first time...  human\n",
            "...                                                 ...    ...\n",
            "2127  news how much of your body is your own n a i t...   ctrl\n",
            "2128  news how do you keep a space station clean n q...   ctrl\n",
            "2129  news the city where you pay a years rent up fr...   ctrl\n",
            "2130  news the bbc news app gives you the best of bb...   ctrl\n",
            "2131  news learn how the bbc is working to strengthe...   ctrl\n",
            "\n",
            "[2132 rows x 2 columns]\n",
            "\n",
            "Data frame for class fair:\n",
            "                                                   text  class\n",
            "0     latest headlines on cnn business latest headli...  human\n",
            "1     china wants to take a victory lap over its han...  human\n",
            "2     coronavirus disinformation creates challenges ...  human\n",
            "3     china coronavirus eating wild animals made ill...  human\n",
            "4     chinas economy could shrink for the first time...  human\n",
            "...                                                 ...    ...\n",
            "2127  how much of your body is your own if im not go...   fair\n",
            "2128  how do you keep a space station clean the astr...   fair\n",
            "2129  the city where you pay a years rent up front a...   fair\n",
            "2130  the bbc news app gives you the best of bbc new...   fair\n",
            "2131  learn how the bbc is working to strengthen tru...   fair\n",
            "\n",
            "[2132 rows x 2 columns]\n",
            "\n",
            "Data frame for class gpt:\n",
            "                                                   text  class\n",
            "0     latest headlines on cnn business latest headli...  human\n",
            "1     china wants to take a victory lap over its han...  human\n",
            "2     coronavirus disinformation creates challenges ...  human\n",
            "3     china coronavirus eating wild animals made ill...  human\n",
            "4     chinas economy could shrink for the first time...  human\n",
            "...                                                 ...    ...\n",
            "2127  how much of your body is your own  n she didnt...    gpt\n",
            "2128  how do you keep a space station clean  n she s...    gpt\n",
            "2129  the city where you pay a years rent up front  ...    gpt\n",
            "2130  the bbc news app gives you the best of bbc new...    gpt\n",
            "2131  learn how the bbc is working to strengthen tru...    gpt\n",
            "\n",
            "[2132 rows x 2 columns]\n",
            "\n",
            "Data frame for class gpt2:\n",
            "                                                   text  class\n",
            "0     latest headlines on cnn business latest headli...  human\n",
            "1     china wants to take a victory lap over its han...  human\n",
            "2     coronavirus disinformation creates challenges ...  human\n",
            "3     china coronavirus eating wild animals made ill...  human\n",
            "4     chinas economy could shrink for the first time...  human\n",
            "...                                                 ...    ...\n",
            "2127  how much of your body is your ownnnwhat is you...   gpt2\n",
            "2128  how do you keep a space station cleannnspace s...   gpt2\n",
            "2129  the city where you pay a years rent up front f...   gpt2\n",
            "2130  the bbc news app gives you the best of bbc new...   gpt2\n",
            "2131  learn how the bbc is working to strengthen tru...   gpt2\n",
            "\n",
            "[2132 rows x 2 columns]\n",
            "\n",
            "Data frame for class gpt3:\n",
            "                                                   text  class\n",
            "0     latest headlines on cnn business latest headli...  human\n",
            "1     china wants to take a victory lap over its han...  human\n",
            "2     coronavirus disinformation creates challenges ...  human\n",
            "3     china coronavirus eating wild animals made ill...  human\n",
            "4     chinas economy could shrink for the first time...  human\n",
            "...                                                 ...    ...\n",
            "2127  how much of your body is your own how much of ...   gpt3\n",
            "2128  how do you keep a space station clean how do y...   gpt3\n",
            "2129  the city where you pay a years rent up front t...   gpt3\n",
            "2130  the bbc news app gives you the best of bbc new...   gpt3\n",
            "2131  learn how the bbc is working to strengthen tru...   gpt3\n",
            "\n",
            "[2132 rows x 2 columns]\n",
            "\n",
            "Data frame for class grover:\n",
            "                                                   text   class\n",
            "0     latest headlines on cnn business latest headli...   human\n",
            "1     china wants to take a victory lap over its han...   human\n",
            "2     coronavirus disinformation creates challenges ...   human\n",
            "3     china coronavirus eating wild animals made ill...   human\n",
            "4     chinas economy could shrink for the first time...   human\n",
            "...                                                 ...     ...\n",
            "2127  how much of your body is your own how much of ...  grover\n",
            "2128  how do you keep a space station clean how do y...  grover\n",
            "2129  the city where you pay a years rent up front t...  grover\n",
            "2130  the bbc news app gives you the best of bbc new...  grover\n",
            "2131  learn how the bbc is working to strengthen tru...  grover\n",
            "\n",
            "[2132 rows x 2 columns]\n",
            "\n",
            "Data frame for class instructgpt:\n",
            "                                                   text        class\n",
            "0     latest headlines on cnn business latest headli...        human\n",
            "1     china wants to take a victory lap over its han...        human\n",
            "2     coronavirus disinformation creates challenges ...        human\n",
            "3     china coronavirus eating wild animals made ill...        human\n",
            "4     chinas economy could shrink for the first time...        human\n",
            "...                                                 ...          ...\n",
            "2127  how much of your body is your own how much of ...  instructgpt\n",
            "2128  how do you keep a space station clean how do y...  instructgpt\n",
            "2129  the city where you pay a years rent up front t...  instructgpt\n",
            "2130  the bbc news app gives you the best of bbc new...  instructgpt\n",
            "2131  learn how the bbc is working to strengthen tru...  instructgpt\n",
            "\n",
            "[2132 rows x 2 columns]\n",
            "\n",
            "Data frame for class pplm:\n",
            "                                                   text  class\n",
            "0     latest headlines on cnn business latest headli...  human\n",
            "1     china wants to take a victory lap over its han...  human\n",
            "2     coronavirus disinformation creates challenges ...  human\n",
            "3     china coronavirus eating wild animals made ill...  human\n",
            "4     chinas economy could shrink for the first time...  human\n",
            "...                                                 ...    ...\n",
            "2127  endoftexthow much of your body is your ownthis...   pplm\n",
            "2128  endoftexthow do you keep a space station clean...   pplm\n",
            "2129  endoftextthe city where you pay a years rent u...   pplm\n",
            "2130  endoftextthe bbc news app gives you the best o...   pplm\n",
            "2131  endoftextlearn how the bbc is working to stren...   pplm\n",
            "\n",
            "[2132 rows x 2 columns]\n",
            "\n",
            "Data frame for class xlm:\n",
            "                                                   text  class\n",
            "0     latest headlines on cnn business latest headli...  human\n",
            "1     china wants to take a victory lap over its han...  human\n",
            "2     coronavirus disinformation creates challenges ...  human\n",
            "3     china coronavirus eating wild animals made ill...  human\n",
            "4     chinas economy could shrink for the first time...  human\n",
            "...                                                 ...    ...\n",
            "2127  how much of your body is your own the like wha...    xlm\n",
            "2128  how do you keep a space station clean s or  2 ...    xlm\n",
            "2129  the city where you pay a years rent up front r...    xlm\n",
            "2130  the bbc news app gives you the best of bbc new...    xlm\n",
            "2131  learn how the bbc is working to strengthen tru...    xlm\n",
            "\n",
            "[2132 rows x 2 columns]\n",
            "\n",
            "Data frame for class xlnet:\n",
            "                                                   text  class\n",
            "0     latest headlines on cnn business latest headli...  human\n",
            "1     china wants to take a victory lap over its han...  human\n",
            "2     coronavirus disinformation creates challenges ...  human\n",
            "3     china coronavirus eating wild animals made ill...  human\n",
            "4     chinas economy could shrink for the first time...  human\n",
            "...                                                 ...    ...\n",
            "2127  how much of your body is your owntaleed to its...  xlnet\n",
            "2128  how do you keep a space station clean how of t...  xlnet\n",
            "2129  the city where you pay a years rent up front t...  xlnet\n",
            "2130  the bbc news app gives you the best of bbc new...  xlnet\n",
            "2131  learn how the bbc is working to strengthen tru...  xlnet\n",
            "\n",
            "[2132 rows x 2 columns]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=class_dataframes[0]\n",
        "df['class'] = df['class'].apply(lambda x: 1 if x==\"human\" else 0)\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "h_fH12g1Im2X"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798,
          "referenced_widgets": [
            "b07b9d9a55de4849b6a28e2a8ff9db24",
            "6e83776b5bd945a491fb172aaac558e9",
            "4bceadfdc16048efb8138b04e4a1858b",
            "a3742fc30b644da98ed6a6cf31905364",
            "e737a1b4f48b492eba7f2470820320c3",
            "60d53d91d4d642fcb398f9c374ec013f",
            "05cec9a212e54b92b31a59ea1aeff578",
            "b3d10ae1ff3b46ada4323b1ae0607724",
            "3034d189146d4b789d0ba197a31ed27c",
            "2d377c0922d54f648fbcdbd763350fd7",
            "6a4d1d0711384b959730636cf7a96f82",
            "10ce79e2ca364b16b66b70aca21bbfc9",
            "63da92c42c804caca16b3bc480e36bea",
            "699dba8853fd479aa7dec4ceb70b6784",
            "6ef7ae566bcb409eb1c155e8c48f24f0",
            "ef7aabffb6b04b28995dd43db1427831",
            "a8ee40ace7fc44268ec5d986e29e9db6",
            "44b770c00a8a44cd803980da739b901f",
            "057d5011807c4aa7bdf7a390a66df0c0",
            "a388d9a931e149cfadbd2e1c5bc0e443",
            "5388041b53344320abe7e5f491371bd3",
            "554dd9d8690c4b4280271ff18f34823c",
            "53aa383cf8db48bc97e74aec9c607c44",
            "e3f01db7ba8548b78fb45ad797e9612c",
            "b2a636768d734ad6a1274a0d1e49e85d",
            "8b19af34be654df8850182ed8b04fdc4",
            "7cca5644df984e1bbfbd4a0a0d262969",
            "401a1d0bf006467e8bf8312e109f0c99",
            "c5db9aba1a7a4e9dad524d84d441a037",
            "028185ac864e48fe8e3533d192de6a8a",
            "98f17c9f55ce47498af41bb76fac5bf7",
            "e4fdd3a05f494ccab577fdef43dfe575",
            "92b30e4acad644c18dedf72c81c02433",
            "8109dbf0509043569d62981056ad1b73",
            "3b01b7887bb947bbafae1b0e4b8c82fc",
            "81bfd750561644a8a2d4b1070d06b8f5",
            "d8edcdfed1f84292a7edf8525b93393d",
            "68b305a4266348e6addab1b46185d544",
            "12ec51c3c28d47acbfef91a8bdf95bd1",
            "5e488d402c00450ab955e409b6c1c17d",
            "02ea831e850f408fb83a3cb88f01fbdd",
            "cbaa6b6b8ff14c0aabe19bfa617b2476",
            "bf7e8e0cacd249a682db1873045ef591",
            "2d5fd2e989554673a85ade78b7b5aa99"
          ]
        },
        "id": "jes43vJzIuF2",
        "outputId": "d30c63e6-33a4-49dc-8ee0-d61d79403cad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b07b9d9a55de4849b6a28e2a8ff9db24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10ce79e2ca364b16b66b70aca21bbfc9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53aa383cf8db48bc97e74aec9c607c44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8109dbf0509043569d62981056ad1b73"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def tokenize_and_encode(text, tokenizer, max_length):\n",
        "    input_ids = tokenizer.encode_plus(text, add_special_tokens=True, max_length=max_length, padding='max_length', truncation=True, return_token_type_ids=False, return_attention_mask=True, return_tensors='pt')\n",
        "    return input_ids['input_ids'], input_ids['attention_mask']"
      ],
      "metadata": {
        "id": "gBicqjQ2JM8Y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloader(df, tokenizer, max_length, batch_size, shuffle=True):\n",
        "    texts = df['text'].values\n",
        "    labels = df['class'].values\n",
        "    \n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    \n",
        "    for text in texts:\n",
        "        input_id, attention_mask = tokenize_and_encode(text, tokenizer, max_length)\n",
        "        input_ids.append(input_id)\n",
        "        attention_masks.append(attention_mask)\n",
        "        \n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "    \n",
        "    dataset = torch.utils.data.TensorDataset(input_ids, attention_masks, labels)\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "nOM3i0BeJRHf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_dataloader, optimizer, device):\n",
        "    model.train()\n",
        "    \n",
        "    for batch in train_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, attention_masks, labels = batch\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "UOVQuOU3JWFf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
        "\n",
        "def evaluate_model(model, val_dataloader, device):\n",
        "    model.eval()\n",
        "    val_loss, val_accuracy = 0, 0\n",
        "    n_val_steps = 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, attention_masks, labels = batch\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_masks, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            preds = logits.argmax(dim=1)\n",
        "            all_preds.extend(preds.tolist())\n",
        "            all_labels.extend(labels.tolist())\n",
        "            val_accuracy += (preds == labels).float().mean().item()\n",
        "            n_val_steps += 1\n",
        "\n",
        "    val_loss /= n_val_steps\n",
        "    val_accuracy /= n_val_steps\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
        "    classification_rep = classification_report(all_labels, all_preds)\n",
        "\n",
        "    return val_loss, val_accuracy, precision, recall, f1, classification_rep\n"
      ],
      "metadata": {
        "id": "ebxP-b-3JYBQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 5\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\").to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "train_dataloader = get_dataloader(train_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "val_dataloader = get_dataloader(test_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "f1_scores = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_model(model, train_dataloader, optimizer, device)\n",
        "    val_loss, val_accuracy, val_precision, val_recall, val_f1, classification_rep = evaluate_model(model, val_dataloader, device)\n",
        "    train_accuracies.append(val_accuracy)  \n",
        "    val_accuracies.append(val_accuracy)  \n",
        "    f1_scores.append(val_f1)  \n",
        "    print(\"HUMAN(1)  VS CTRL(0)\")\n",
        "    print(f\"Epoch {epoch + 1} Val Loss: {val_loss:.3f}, Val Accuracy: {val_accuracy:.3f}, Val Precision: {val_precision:.3f}, Val Recall: {val_recall:.3f}, Val F1: {val_f1:.3f}\")\n",
        "    print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTjBkC4IJajC",
        "outputId": "c9b2b75d-b227-4f31-c78d-fe85bd13db48"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HUMAN(1)  VS CTRL(0)\n",
            "Epoch 1 Val Loss: 0.005, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "HUMAN(1)  VS CTRL(0)\n",
            "Epoch 2 Val Loss: 0.001, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "HUMAN(1)  VS CTRL(0)\n",
            "Epoch 3 Val Loss: 0.001, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "HUMAN(1)  VS CTRL(0)\n",
            "Epoch 4 Val Loss: 0.000, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "HUMAN(1)  VS CTRL(0)\n",
            "Epoch 5 Val Loss: 0.000, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=class_dataframes[1]\n",
        "df['class'] = df['class'].apply(lambda x: 1 if x==\"human\" else 0)\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 5\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\").to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "train_dataloader = get_dataloader(train_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "val_dataloader = get_dataloader(test_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "f1_scores = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_model(model, train_dataloader, optimizer, device)\n",
        "    val_loss, val_accuracy, val_precision, val_recall, val_f1, classification_rep = evaluate_model(model, val_dataloader, device)\n",
        "    train_accuracies.append(val_accuracy) \n",
        "    val_accuracies.append(val_accuracy)  \n",
        "    f1_scores.append(val_f1)  \n",
        "    print(\"HUMAN(1)  VS fair(0)\")\n",
        "    print(f\"Epoch {epoch + 1} Val Loss: {val_loss:.3f}, Val Accuracy: {val_accuracy:.3f}, Val Precision: {val_precision:.3f}, Val Recall: {val_recall:.3f}, Val F1: {val_f1:.3f}\")\n",
        "    print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlNBCDddX-O5",
        "outputId": "57746f2b-7a8a-4180-8570-00a2f8ac270f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HUMAN(1)  VS fair(0)\n",
            "Epoch 1 Val Loss: 0.397, Val Accuracy: 0.835, Val Precision: 0.862, Val Recall: 0.836, Val F1: 0.833\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.97      0.86       217\n",
            "           1       0.96      0.70      0.81       210\n",
            "\n",
            "    accuracy                           0.84       427\n",
            "   macro avg       0.86      0.83      0.83       427\n",
            "weighted avg       0.86      0.84      0.83       427\n",
            "\n",
            "HUMAN(1)  VS fair(0)\n",
            "Epoch 2 Val Loss: 0.290, Val Accuracy: 0.873, Val Precision: 0.874, Val Recall: 0.874, Val F1: 0.874\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88       217\n",
            "           1       0.87      0.87      0.87       210\n",
            "\n",
            "    accuracy                           0.87       427\n",
            "   macro avg       0.87      0.87      0.87       427\n",
            "weighted avg       0.87      0.87      0.87       427\n",
            "\n",
            "HUMAN(1)  VS fair(0)\n",
            "Epoch 3 Val Loss: 0.352, Val Accuracy: 0.881, Val Precision: 0.901, Val Recall: 0.883, Val F1: 0.881\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.99      0.90       217\n",
            "           1       0.99      0.77      0.87       210\n",
            "\n",
            "    accuracy                           0.88       427\n",
            "   macro avg       0.90      0.88      0.88       427\n",
            "weighted avg       0.90      0.88      0.88       427\n",
            "\n",
            "HUMAN(1)  VS fair(0)\n",
            "Epoch 4 Val Loss: 0.125, Val Accuracy: 0.955, Val Precision: 0.958, Val Recall: 0.958, Val F1: 0.958\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.94      0.96       217\n",
            "           1       0.94      0.97      0.96       210\n",
            "\n",
            "    accuracy                           0.96       427\n",
            "   macro avg       0.96      0.96      0.96       427\n",
            "weighted avg       0.96      0.96      0.96       427\n",
            "\n",
            "HUMAN(1)  VS fair(0)\n",
            "Epoch 5 Val Loss: 0.104, Val Accuracy: 0.969, Val Precision: 0.970, Val Recall: 0.970, Val F1: 0.970\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97       217\n",
            "           1       0.96      0.98      0.97       210\n",
            "\n",
            "    accuracy                           0.97       427\n",
            "   macro avg       0.97      0.97      0.97       427\n",
            "weighted avg       0.97      0.97      0.97       427\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=class_dataframes[2]\n",
        "df['class'] = df['class'].apply(lambda x: 1 if x==\"human\" else 0)\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 5\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\").to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "train_dataloader = get_dataloader(train_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "val_dataloader = get_dataloader(test_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "f1_scores = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_model(model, train_dataloader, optimizer, device)\n",
        "    val_loss, val_accuracy, val_precision, val_recall, val_f1, classification_rep = evaluate_model(model, val_dataloader, device)\n",
        "    train_accuracies.append(val_accuracy) \n",
        "    val_accuracies.append(val_accuracy)  \n",
        "    f1_scores.append(val_f1)  \n",
        "    print(\"HUMAN(1)  VS gpt(0)\")\n",
        "    print(f\"Epoch {epoch + 1} Val Loss: {val_loss:.3f}, Val Accuracy: {val_accuracy:.3f}, Val Precision: {val_precision:.3f}, Val Recall: {val_recall:.3f}, Val F1: {val_f1:.3f}\")\n",
        "    print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da5RAKwtPZgh",
        "outputId": "6ab379f7-70e1-49f2-e443-14d0964bef1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HUMAN(1)  VS gpt(0)\n",
            "Epoch 1 Val Loss: 0.023, Val Accuracy: 0.993, Val Precision: 0.993, Val Recall: 0.993, Val F1: 0.993\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       217\n",
            "           1       1.00      0.99      0.99       210\n",
            "\n",
            "    accuracy                           0.99       427\n",
            "   macro avg       0.99      0.99      0.99       427\n",
            "weighted avg       0.99      0.99      0.99       427\n",
            "\n",
            "HUMAN(1)  VS gpt(0)\n",
            "Epoch 2 Val Loss: 0.004, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "HUMAN(1)  VS gpt(0)\n",
            "Epoch 3 Val Loss: 0.002, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "HUMAN(1)  VS gpt(0)\n",
            "Epoch 4 Val Loss: 0.001, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "HUMAN(1)  VS gpt(0)\n",
            "Epoch 5 Val Loss: 0.001, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=class_dataframes[3]\n",
        "df['class'] = df['class'].apply(lambda x: 1 if x==\"human\" else 0)\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 5\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\").to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "train_dataloader = get_dataloader(train_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "val_dataloader = get_dataloader(test_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "f1_scores = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_model(model, train_dataloader, optimizer, device)\n",
        "    val_loss, val_accuracy, val_precision, val_recall, val_f1, classification_rep = evaluate_model(model, val_dataloader, device)\n",
        "    train_accuracies.append(val_accuracy)  \n",
        "    val_accuracies.append(val_accuracy) \n",
        "    f1_scores.append(val_f1)  \n",
        "    print(\"HUMAN(1)  VS gpt2(0)\")\n",
        "    print(f\"Epoch {epoch + 1} Val Loss: {val_loss:.3f}, Val Accuracy: {val_accuracy:.3f}, Val Precision: {val_precision:.3f}, Val Recall: {val_recall:.3f}, Val F1: {val_f1:.3f}\")\n",
        "    print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKNgILqTY3ys",
        "outputId": "d7bb16bd-e1b1-4617-ee61-7c81c3fe11a3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HUMAN(1)  VS gpt2(0)\n",
            "Epoch 1 Val Loss: 0.027, Val Accuracy: 0.991, Val Precision: 0.991, Val Recall: 0.991, Val F1: 0.991\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99       217\n",
            "           1       0.98      1.00      0.99       210\n",
            "\n",
            "    accuracy                           0.99       427\n",
            "   macro avg       0.99      0.99      0.99       427\n",
            "weighted avg       0.99      0.99      0.99       427\n",
            "\n",
            "HUMAN(1)  VS gpt2(0)\n",
            "Epoch 2 Val Loss: 0.014, Val Accuracy: 0.998, Val Precision: 0.998, Val Recall: 0.998, Val F1: 0.998\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "HUMAN(1)  VS gpt2(0)\n",
            "Epoch 3 Val Loss: 0.009, Val Accuracy: 0.998, Val Precision: 0.998, Val Recall: 0.998, Val F1: 0.998\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "HUMAN(1)  VS gpt2(0)\n",
            "Epoch 4 Val Loss: 0.007, Val Accuracy: 0.995, Val Precision: 0.995, Val Recall: 0.995, Val F1: 0.995\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "HUMAN(1)  VS gpt2(0)\n",
            "Epoch 5 Val Loss: 0.006, Val Accuracy: 0.995, Val Precision: 0.995, Val Recall: 0.995, Val F1: 0.995\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=class_dataframes[4]\n",
        "df['class'] = df['class'].apply(lambda x: 1 if x==\"human\" else 0)\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 5\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\").to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "train_dataloader = get_dataloader(train_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "val_dataloader = get_dataloader(test_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "f1_scores = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_model(model, train_dataloader, optimizer, device)\n",
        "    val_loss, val_accuracy, val_precision, val_recall, val_f1, classification_rep = evaluate_model(model, val_dataloader, device)\n",
        "    train_accuracies.append(val_accuracy)  \n",
        "    val_accuracies.append(val_accuracy)  \n",
        "    f1_scores.append(val_f1)  \n",
        "    print(\"HUMAN(1)  VS gpt3(0)\")\n",
        "    print(f\"Epoch {epoch + 1} Val Loss: {val_loss:.3f}, Val Accuracy: {val_accuracy:.3f}, Val Precision: {val_precision:.3f}, Val Recall: {val_recall:.3f}, Val F1: {val_f1:.3f}\")\n",
        "    print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n74VUYp3Y9oZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8361082-a776-41f4-c23b-82374c54c532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HUMAN(1)  VS gpt3(0)\n",
            "Epoch 1 Val Loss: 0.125, Val Accuracy: 0.962, Val Precision: 0.964, Val Recall: 0.963, Val F1: 0.962\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       217\n",
            "           1       0.99      0.93      0.96       210\n",
            "\n",
            "    accuracy                           0.96       427\n",
            "   macro avg       0.96      0.96      0.96       427\n",
            "weighted avg       0.96      0.96      0.96       427\n",
            "\n",
            "HUMAN(1)  VS gpt3(0)\n",
            "Epoch 2 Val Loss: 0.088, Val Accuracy: 0.975, Val Precision: 0.974, Val Recall: 0.974, Val F1: 0.974\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97       217\n",
            "           1       0.98      0.97      0.97       210\n",
            "\n",
            "    accuracy                           0.97       427\n",
            "   macro avg       0.97      0.97      0.97       427\n",
            "weighted avg       0.97      0.97      0.97       427\n",
            "\n",
            "HUMAN(1)  VS gpt3(0)\n",
            "Epoch 3 Val Loss: 0.144, Val Accuracy: 0.970, Val Precision: 0.971, Val Recall: 0.970, Val F1: 0.970\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97       217\n",
            "           1       0.99      0.94      0.97       210\n",
            "\n",
            "    accuracy                           0.97       427\n",
            "   macro avg       0.97      0.97      0.97       427\n",
            "weighted avg       0.97      0.97      0.97       427\n",
            "\n",
            "HUMAN(1)  VS gpt3(0)\n",
            "Epoch 4 Val Loss: 0.112, Val Accuracy: 0.976, Val Precision: 0.977, Val Recall: 0.977, Val F1: 0.977\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98       217\n",
            "           1       0.98      0.97      0.98       210\n",
            "\n",
            "    accuracy                           0.98       427\n",
            "   macro avg       0.98      0.98      0.98       427\n",
            "weighted avg       0.98      0.98      0.98       427\n",
            "\n",
            "HUMAN(1)  VS gpt3(0)\n",
            "Epoch 5 Val Loss: 0.121, Val Accuracy: 0.978, Val Precision: 0.979, Val Recall: 0.979, Val F1: 0.979\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       217\n",
            "           1       1.00      0.96      0.98       210\n",
            "\n",
            "    accuracy                           0.98       427\n",
            "   macro avg       0.98      0.98      0.98       427\n",
            "weighted avg       0.98      0.98      0.98       427\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=class_dataframes[5]\n",
        "df['class'] = df['class'].apply(lambda x: 1 if x==\"human\" else 0)\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 5\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\").to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "train_dataloader = get_dataloader(train_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "val_dataloader = get_dataloader(test_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "f1_scores = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_model(model, train_dataloader, optimizer, device)\n",
        "    val_loss, val_accuracy, val_precision, val_recall, val_f1, classification_rep = evaluate_model(model, val_dataloader, device)\n",
        "    train_accuracies.append(val_accuracy)  \n",
        "    val_accuracies.append(val_accuracy)  \n",
        "    f1_scores.append(val_f1)  \n",
        "    print(\"HUMAN(1)  VS grover(0)\")\n",
        "    print(f\"Epoch {epoch + 1} Val Loss: {val_loss:.3f}, Val Accuracy: {val_accuracy:.3f}, Val Precision: {val_precision:.3f}, Val Recall: {val_recall:.3f}, Val F1: {val_f1:.3f}\")\n",
        "    print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOEldANtPoAK",
        "outputId": "3e04d86f-0802-4999-87f0-b2ebf5b9aa58"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HUMAN(1)  VS grover(0)\n",
            "Epoch 1 Val Loss: 0.103, Val Accuracy: 0.968, Val Precision: 0.968, Val Recall: 0.967, Val F1: 0.967\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.94      0.97       217\n",
            "           1       0.95      0.99      0.97       210\n",
            "\n",
            "    accuracy                           0.97       427\n",
            "   macro avg       0.97      0.97      0.97       427\n",
            "weighted avg       0.97      0.97      0.97       427\n",
            "\n",
            "HUMAN(1)  VS grover(0)\n",
            "Epoch 2 Val Loss: 0.085, Val Accuracy: 0.968, Val Precision: 0.969, Val Recall: 0.967, Val F1: 0.967\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97       217\n",
            "           1       0.94      1.00      0.97       210\n",
            "\n",
            "    accuracy                           0.97       427\n",
            "   macro avg       0.97      0.97      0.97       427\n",
            "weighted avg       0.97      0.97      0.97       427\n",
            "\n",
            "HUMAN(1)  VS grover(0)\n",
            "Epoch 3 Val Loss: 0.112, Val Accuracy: 0.965, Val Precision: 0.967, Val Recall: 0.965, Val F1: 0.965\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.93      0.96       217\n",
            "           1       0.93      1.00      0.97       210\n",
            "\n",
            "    accuracy                           0.96       427\n",
            "   macro avg       0.97      0.97      0.96       427\n",
            "weighted avg       0.97      0.96      0.96       427\n",
            "\n",
            "HUMAN(1)  VS grover(0)\n",
            "Epoch 4 Val Loss: 0.066, Val Accuracy: 0.979, Val Precision: 0.979, Val Recall: 0.979, Val F1: 0.979\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98       217\n",
            "           1       0.97      0.99      0.98       210\n",
            "\n",
            "    accuracy                           0.98       427\n",
            "   macro avg       0.98      0.98      0.98       427\n",
            "weighted avg       0.98      0.98      0.98       427\n",
            "\n",
            "HUMAN(1)  VS grover(0)\n",
            "Epoch 5 Val Loss: 0.129, Val Accuracy: 0.964, Val Precision: 0.967, Val Recall: 0.965, Val F1: 0.965\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.96       217\n",
            "           1       0.94      1.00      0.97       210\n",
            "\n",
            "    accuracy                           0.96       427\n",
            "   macro avg       0.97      0.97      0.96       427\n",
            "weighted avg       0.97      0.96      0.96       427\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=class_dataframes[6]\n",
        "df['class'] = df['class'].apply(lambda x: 1 if x==\"human\" else 0)\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 5\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\").to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "train_dataloader = get_dataloader(train_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "val_dataloader = get_dataloader(test_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "f1_scores = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_model(model, train_dataloader, optimizer, device)\n",
        "    val_loss, val_accuracy, val_precision, val_recall, val_f1, classification_rep = evaluate_model(model, val_dataloader, device)\n",
        "    train_accuracies.append(val_accuracy) \n",
        "    val_accuracies.append(val_accuracy)  \n",
        "    f1_scores.append(val_f1)  \n",
        "    print(\"HUMAN(1)  VS InstructGPT(0)\")\n",
        "    print(f\"Epoch {epoch + 1} Val Loss: {val_loss:.3f}, Val Accuracy: {val_accuracy:.3f}, Val Precision: {val_precision:.3f}, Val Recall: {val_recall:.3f}, Val F1: {val_f1:.3f}\")\n",
        "    print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TSRqg7MbZRWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a12084-9b25-471a-cb30-64e1899d65f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HUMAN(1)  VS InstructGPT(0)\n",
            "Epoch 1 Val Loss: 0.105, Val Accuracy: 0.963, Val Precision: 0.963, Val Recall: 0.963, Val F1: 0.963\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96       217\n",
            "           1       0.98      0.95      0.96       210\n",
            "\n",
            "    accuracy                           0.96       427\n",
            "   macro avg       0.96      0.96      0.96       427\n",
            "weighted avg       0.96      0.96      0.96       427\n",
            "\n",
            "HUMAN(1)  VS InstructGPT(0)\n",
            "Epoch 2 Val Loss: 0.103, Val Accuracy: 0.970, Val Precision: 0.971, Val Recall: 0.970, Val F1: 0.970\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97       217\n",
            "           1       1.00      0.94      0.97       210\n",
            "\n",
            "    accuracy                           0.97       427\n",
            "   macro avg       0.97      0.97      0.97       427\n",
            "weighted avg       0.97      0.97      0.97       427\n",
            "\n",
            "HUMAN(1)  VS InstructGPT(0)\n",
            "Epoch 3 Val Loss: 0.110, Val Accuracy: 0.968, Val Precision: 0.968, Val Recall: 0.967, Val F1: 0.967\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.95      0.97       217\n",
            "           1       0.95      0.99      0.97       210\n",
            "\n",
            "    accuracy                           0.97       427\n",
            "   macro avg       0.97      0.97      0.97       427\n",
            "weighted avg       0.97      0.97      0.97       427\n",
            "\n",
            "HUMAN(1)  VS InstructGPT(0)\n",
            "Epoch 4 Val Loss: 0.102, Val Accuracy: 0.969, Val Precision: 0.971, Val Recall: 0.970, Val F1: 0.970\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97       217\n",
            "           1       0.99      0.94      0.97       210\n",
            "\n",
            "    accuracy                           0.97       427\n",
            "   macro avg       0.97      0.97      0.97       427\n",
            "weighted avg       0.97      0.97      0.97       427\n",
            "\n",
            "HUMAN(1)  VS InstructGPT(0)\n",
            "Epoch 5 Val Loss: 0.105, Val Accuracy: 0.972, Val Precision: 0.973, Val Recall: 0.972, Val F1: 0.972\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97       217\n",
            "           1       0.99      0.95      0.97       210\n",
            "\n",
            "    accuracy                           0.97       427\n",
            "   macro avg       0.97      0.97      0.97       427\n",
            "weighted avg       0.97      0.97      0.97       427\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=class_dataframes[7]\n",
        "df['class'] = df['class'].apply(lambda x: 1 if x==\"human\" else 0)\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 5\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\").to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "train_dataloader = get_dataloader(train_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "val_dataloader = get_dataloader(test_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "f1_scores = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_model(model, train_dataloader, optimizer, device)\n",
        "    val_loss, val_accuracy, val_precision, val_recall, val_f1, classification_rep = evaluate_model(model, val_dataloader, device)\n",
        "    train_accuracies.append(val_accuracy)  \n",
        "    val_accuracies.append(val_accuracy)  \n",
        "    f1_scores.append(val_f1)  \n",
        "    print(\"HUMAN(1)  VS PPLM(0)\")\n",
        "    print(f\"Epoch {epoch + 1} Val Loss: {val_loss:.3f}, Val Accuracy: {val_accuracy:.3f}, Val Precision: {val_precision:.3f}, Val Recall: {val_recall:.3f}, Val F1: {val_f1:.3f}\")\n",
        "    print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KifV8l5gZWZn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc904380-9c67-4deb-a2b0-83eba72ed2d8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HUMAN(1)  VS PPLM(0)\n",
            "Epoch 1 Val Loss: 0.010, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "HUMAN(1)  VS PPLM(0)\n",
            "Epoch 2 Val Loss: 0.002, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "HUMAN(1)  VS PPLM(0)\n",
            "Epoch 3 Val Loss: 0.001, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "HUMAN(1)  VS PPLM(0)\n",
            "Epoch 4 Val Loss: 0.001, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "HUMAN(1)  VS PPLM(0)\n",
            "Epoch 5 Val Loss: 0.000, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=class_dataframes[8]\n",
        "df['class'] = df['class'].apply(lambda x: 1 if x==\"human\" else 0)\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 5\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\").to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "train_dataloader = get_dataloader(train_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "val_dataloader = get_dataloader(test_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "f1_scores = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_model(model, train_dataloader, optimizer, device)\n",
        "    val_loss, val_accuracy, val_precision, val_recall, val_f1, classification_rep = evaluate_model(model, val_dataloader, device)\n",
        "    train_accuracies.append(val_accuracy)  \n",
        "    val_accuracies.append(val_accuracy)  \n",
        "    f1_scores.append(val_f1)  \n",
        "    print(f\"Epoch {epoch + 1} Val Loss: {val_loss:.3f}, Val Accuracy: {val_accuracy:.3f}, Val Precision: {val_precision:.3f}, Val Recall: {val_recall:.3f}, Val F1: {val_f1:.3f}\")\n",
        "    print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wAqzGnZ0PsrS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "130e512e-78ad-4d47-a275-34de774dbca6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Val Loss: 0.004, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "Epoch 2 Val Loss: 0.001, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "Epoch 3 Val Loss: 0.001, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "Epoch 4 Val Loss: 0.000, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "Epoch 5 Val Loss: 0.000, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=class_dataframes[9]\n",
        "df['class'] = df['class'].apply(lambda x: 1 if x==\"human\" else 0)\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 5\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\").to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "train_dataloader = get_dataloader(train_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "val_dataloader = get_dataloader(test_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "f1_scores = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_model(model, train_dataloader, optimizer, device)\n",
        "    val_loss, val_accuracy, val_precision, val_recall, val_f1, classification_rep = evaluate_model(model, val_dataloader, device)\n",
        "    train_accuracies.append(val_accuracy)  \n",
        "    val_accuracies.append(val_accuracy)  \n",
        "    f1_scores.append(val_f1)  \n",
        "    print(\"HUMAN(1)  VS XLNET(0)\")\n",
        "    print(f\"Epoch {epoch + 1} Val Loss: {val_loss:.3f}, Val Accuracy: {val_accuracy:.3f}, Val Precision: {val_precision:.3f}, Val Recall: {val_recall:.3f}, Val F1: {val_f1:.3f}\")\n",
        "    print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2FhllKBP7P7",
        "outputId": "900d191c-cd92-4dea-c4e7-0f0241881652"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HUMAN(1)  VS XLNET(0)\n",
            "Epoch 1 Val Loss: 0.005, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "HUMAN(1)  VS XLNET(0)\n",
            "Epoch 2 Val Loss: 0.002, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "HUMAN(1)  VS XLNET(0)\n",
            "Epoch 3 Val Loss: 0.001, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "HUMAN(1)  VS XLNET(0)\n",
            "Epoch 4 Val Loss: 0.001, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n",
            "HUMAN(1)  VS XLNET(0)\n",
            "Epoch 5 Val Loss: 0.000, Val Accuracy: 1.000, Val Precision: 1.000, Val Recall: 1.000, Val F1: 1.000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       217\n",
            "           1       1.00      1.00      1.00       210\n",
            "\n",
            "    accuracy                           1.00       427\n",
            "   macro avg       1.00      1.00      1.00       427\n",
            "weighted avg       1.00      1.00      1.00       427\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KP-5kq_-QF3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unseen_df = df1  \n",
        "\n",
        "unseen_dataloader = get_dataloader(unseen_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n",
        "\n",
        "\n",
        "unseen_loss, unseen_accuracy, unseen_precision, unseen_recall, unseen_f1, unseen_classification_rep = evaluate_model(model, unseen_dataloader, device)\n",
        "\n",
        "\n",
        "print(\"Classification Report for REDDIt unseen Data:\")\n",
        "print(unseen_classification_rep)\n",
        "print(f\"Accuracy: {unseen_accuracy:.3f}\")\n",
        "print(f\"Precision: {unseen_precision:.3f}\")\n",
        "print(f\"Recall: {unseen_recall:.3f}\")\n",
        "print(f\"F1-Score: {unseen_f1:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEl-yrlqLEi5",
        "outputId": "f0f2ff4f-df9c-4105-8edf-72842d63cb50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for REDDIt unseen Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.94      0.77      1224\n",
            "           1       0.39      0.07      0.11       652\n",
            "\n",
            "    accuracy                           0.64      1876\n",
            "   macro avg       0.52      0.51      0.44      1876\n",
            "weighted avg       0.56      0.64      0.54      1876\n",
            "\n",
            "Accuracy: 0.637\n",
            "Precision: 0.562\n",
            "Recall: 0.639\n",
            "F1-Score: 0.544\n"
          ]
        }
      ]
    }
  ]
}