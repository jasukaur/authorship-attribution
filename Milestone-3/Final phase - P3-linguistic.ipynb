{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82621527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b65602b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11721</th>\n",
       "      <td>how much of your body is your own how much of ...</td>\n",
       "      <td>instructgpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11722</th>\n",
       "      <td>how do you keep a space station clean how do y...</td>\n",
       "      <td>instructgpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11723</th>\n",
       "      <td>the city where you pay a years rent up front t...</td>\n",
       "      <td>instructgpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11724</th>\n",
       "      <td>the bbc news app gives you the best of bbc new...</td>\n",
       "      <td>instructgpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11725</th>\n",
       "      <td>learn how the bbc is working to strengthen tru...</td>\n",
       "      <td>instructgpt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text        class\n",
       "11721  how much of your body is your own how much of ...  instructgpt\n",
       "11722  how do you keep a space station clean how do y...  instructgpt\n",
       "11723  the city where you pay a years rent up front t...  instructgpt\n",
       "11724  the bbc news app gives you the best of bbc new...  instructgpt\n",
       "11725  learn how the bbc is working to strengthen tru...  instructgpt"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '/home/arsh/Jasleen/Spring 2023/NLP/Group Project/Authorship-Attribution-for-Neural-Text-Generation-master/data/'\n",
    "\n",
    "combined = pd.read_csv(data_path + 'input.csv')\n",
    "combined.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9efb0e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afea83a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl       0.97      1.00      0.98       203\n",
      "        fair       0.50      0.60      0.55       211\n",
      "         gpt       0.98      1.00      0.99       205\n",
      "        gpt2       0.54      0.76      0.63       213\n",
      "        gpt3       0.44      0.51      0.47       233\n",
      "      grover       0.76      0.41      0.54       211\n",
      "       human       0.82      0.71      0.76       213\n",
      " instructgpt       0.66      0.70      0.68       223\n",
      "        pplm       0.76      0.57      0.65       207\n",
      "         xlm       0.98      0.99      0.99       219\n",
      "       xlnet       0.99      0.96      0.98       208\n",
      "\n",
      "    accuracy                           0.74      2346\n",
      "   macro avg       0.76      0.75      0.75      2346\n",
      "weighted avg       0.76      0.74      0.74      2346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random forrest with bag of words\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined['text'], combined['class'], test_size=0.2)\n",
    "\n",
    "# Create a CountVectorizer object for extracting features\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Random Forest classifier on the training set\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec797886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text to predict: In this code, we first load the data from the CSV file into a pandas DataFrame. Then, we define a preprocessing function that tokenizes the text, performs part-of-speech tagging, lemmatizes the tokens, and removes stop words. We apply this preprocessing function to the text column and obtain the preprocessed text.\n",
      "Prediction: human\n"
     ]
    }
   ],
   "source": [
    "text = input(\"Enter text to predict: \")\n",
    "X_new = vectorizer.transform([text])\n",
    "prediction = rfc.predict(X_new)[0]\n",
    "print('Prediction:', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65222ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0d2136b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl       0.96      0.98      0.97       210\n",
      "        fair       0.50      0.58      0.53       228\n",
      "         gpt       0.98      1.00      0.99       216\n",
      "        gpt2       0.49      0.74      0.59       183\n",
      "        gpt3       0.48      0.51      0.49       215\n",
      "      grover       0.59      0.45      0.51       223\n",
      "       human       0.87      0.61      0.71       229\n",
      " instructgpt       0.58      0.75      0.65       195\n",
      "        pplm       0.88      0.55      0.67       233\n",
      "         xlm       1.00      0.97      0.98       215\n",
      "       xlnet       0.97      0.99      0.98       199\n",
      "\n",
      "    accuracy                           0.73      2346\n",
      "   macro avg       0.75      0.74      0.73      2346\n",
      "weighted avg       0.76      0.73      0.73      2346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with TF-IDF\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined['text'], combined['class'], test_size=0.2)\n",
    "\n",
    "# Create a TF-IDF vectorizer object for extracting features\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Random Forest classifier on the training set\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f8e897a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text to predict: dreanms,,\n",
      "Prediction: gpt2\n"
     ]
    }
   ],
   "source": [
    "text = input(\"Enter text to predict: \")\n",
    "X_new = vectorizer.transform([text])\n",
    "prediction = rfc.predict(X_new)[0]\n",
    "print('Prediction:', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4de80e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc652d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0079b45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl       1.00      1.00      1.00       200\n",
      "        fair       0.60      0.78      0.68       226\n",
      "         gpt       1.00      1.00      1.00       225\n",
      "        gpt2       0.70      0.61      0.65       212\n",
      "        gpt3       0.52      0.62      0.57       213\n",
      "      grover       0.61      0.69      0.65       218\n",
      "       human       0.75      0.62      0.68       212\n",
      " instructgpt       0.67      0.66      0.67       210\n",
      "        pplm       0.90      0.61      0.73       217\n",
      "         xlm       1.00      1.00      1.00       203\n",
      "       xlnet       1.00      0.98      0.99       210\n",
      "\n",
      "    accuracy                           0.78      2346\n",
      "   macro avg       0.80      0.78      0.78      2346\n",
      "weighted avg       0.79      0.78      0.78      2346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM with bag of words\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined['text'], combined['class'], test_size=0.2)\n",
    "\n",
    "# Create a CountVectorizer object for extracting features\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a SVM classifier on the training set\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e991f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be538b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with tfidf\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined['text'], combined['class'], test_size=0.2)\n",
    "\n",
    "# Create a TfidfVectorizer object for extracting features\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a SVM classifier on the training set\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4af421",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = input(\"Enter text to predict: \")\n",
    "X_new = vectorizer.transform([text])\n",
    "prediction = rfc.predict(X_new)[0]\n",
    "print('Prediction:', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ff3a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06baac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Code with linguistic Analysis- Phase 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d6303c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74adb788",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa6795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_discourse_structure(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    num_sentences = len(sentences)\n",
    "    num_words = len(word_tokenize(text))\n",
    "    avg_words_per_sentence = num_words / num_sentences\n",
    "\n",
    "    return [num_sentences, num_words, avg_words_per_sentence]\n",
    "\n",
    "data['discourse_structure'] = data['text'].apply(extract_discourse_structure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c9dceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pos_statistics(text):\n",
    "    words = word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    pos_counts = nltk.FreqDist(tag for word, tag in pos_tags)\n",
    "\n",
    "    return pos_counts\n",
    "\n",
    "data['pos_statistics'] = data['text'].apply(extract_pos_statistics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22ab2e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_sentence_length(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    num_sentences = len(sentences)\n",
    "    num_words = len(word_tokenize(text))\n",
    "    avg_words_per_sentence = num_words / num_sentences\n",
    "\n",
    "    return avg_words_per_sentence\n",
    "\n",
    "data['avg_sentence_length'] = data['text'].apply(calculate_average_sentence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e23dac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ttr(text):\n",
    "    words = word_tokenize(text)\n",
    "    num_tokens = len(words)\n",
    "    num_types = len(set(words))\n",
    "    ttr = num_types / num_tokens\n",
    "\n",
    "    return ttr\n",
    "\n",
    "data['ttr'] = data['text'].apply(calculate_ttr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b44ede45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_clauses_per_sentence(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    num_sentences = len(sentences)\n",
    "    num_clauses = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        clause_count = sentence.count(',') + 1  # Assuming clauses are separated by commas\n",
    "        num_clauses += clause_count\n",
    "\n",
    "    avg_clauses_per_sentence = num_clauses / num_sentences\n",
    "\n",
    "    return avg_clauses_per_sentence\n",
    "\n",
    "data['avg_clauses_per_sentence'] = data['text'].apply(calculate_average_clauses_per_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a0301dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['discourse_structure', 'pos_statistics', 'avg_sentence_length', 'ttr', 'avg_clauses_per_sentence']]\n",
    "y = data['class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "86fd4ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_structure</th>\n",
       "      <th>pos_statistics</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>ttr</th>\n",
       "      <th>avg_clauses_per_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 48, 48.0]</td>\n",
       "      <td>{'NN': 6, 'NNS': 7, 'PRP': 4, 'VBP': 2, 'VBG':...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 293, 293.0]</td>\n",
       "      <td>{'JJ': 30, 'NNS': 18, 'TO': 15, 'VB': 26, 'DT'...</td>\n",
       "      <td>293.0</td>\n",
       "      <td>0.508532</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 299, 299.0]</td>\n",
       "      <td>{'NN': 70, 'VBP': 5, 'DT': 44, 'JJ': 24, 'IN':...</td>\n",
       "      <td>299.0</td>\n",
       "      <td>0.444816</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 371, 371.0]</td>\n",
       "      <td>{'RB': 14, 'JJ': 28, 'NN': 80, 'IN': 48, 'NNS'...</td>\n",
       "      <td>371.0</td>\n",
       "      <td>0.576819</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 474, 474.0]</td>\n",
       "      <td>{'WRB': 6, 'NN': 75, 'VBD': 20, 'JJ': 41, 'CC'...</td>\n",
       "      <td>474.0</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11721</th>\n",
       "      <td>[1, 497, 497.0]</td>\n",
       "      <td>{'NN': 1, 'NNS': 488, 'VBZ': 5, 'RB': 1, 'IN': 2}</td>\n",
       "      <td>497.0</td>\n",
       "      <td>0.012072</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11722</th>\n",
       "      <td>[1, 458, 458.0]</td>\n",
       "      <td>{'NN': 32, 'CC': 7, 'VB': 6, 'DT': 18, 'NNS': ...</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.203057</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11723</th>\n",
       "      <td>[1, 410, 410.0]</td>\n",
       "      <td>{'VBG': 8, 'NN': 79, 'IN': 62, 'JJ': 37, 'VBD'...</td>\n",
       "      <td>410.0</td>\n",
       "      <td>0.482927</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11724</th>\n",
       "      <td>[1, 746, 746.0]</td>\n",
       "      <td>{'NN': 128, 'CC': 43, 'DT': 49, 'NNS': 40, 'TO...</td>\n",
       "      <td>746.0</td>\n",
       "      <td>0.454424</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11725</th>\n",
       "      <td>[1, 401, 401.0]</td>\n",
       "      <td>{'JJ': 28, 'NNS': 38, 'VBP': 19, 'VBG': 16, 'R...</td>\n",
       "      <td>401.0</td>\n",
       "      <td>0.456359</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11726 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      discourse_structure                                     pos_statistics  \\\n",
       "0           [1, 48, 48.0]  {'NN': 6, 'NNS': 7, 'PRP': 4, 'VBP': 2, 'VBG':...   \n",
       "1         [1, 293, 293.0]  {'JJ': 30, 'NNS': 18, 'TO': 15, 'VB': 26, 'DT'...   \n",
       "2         [1, 299, 299.0]  {'NN': 70, 'VBP': 5, 'DT': 44, 'JJ': 24, 'IN':...   \n",
       "3         [1, 371, 371.0]  {'RB': 14, 'JJ': 28, 'NN': 80, 'IN': 48, 'NNS'...   \n",
       "4         [1, 474, 474.0]  {'WRB': 6, 'NN': 75, 'VBD': 20, 'JJ': 41, 'CC'...   \n",
       "...                   ...                                                ...   \n",
       "11721     [1, 497, 497.0]  {'NN': 1, 'NNS': 488, 'VBZ': 5, 'RB': 1, 'IN': 2}   \n",
       "11722     [1, 458, 458.0]  {'NN': 32, 'CC': 7, 'VB': 6, 'DT': 18, 'NNS': ...   \n",
       "11723     [1, 410, 410.0]  {'VBG': 8, 'NN': 79, 'IN': 62, 'JJ': 37, 'VBD'...   \n",
       "11724     [1, 746, 746.0]  {'NN': 128, 'CC': 43, 'DT': 49, 'NNS': 40, 'TO...   \n",
       "11725     [1, 401, 401.0]  {'JJ': 28, 'NNS': 38, 'VBP': 19, 'VBG': 16, 'R...   \n",
       "\n",
       "       avg_sentence_length       ttr  avg_clauses_per_sentence  \n",
       "0                     48.0  0.750000                       1.0  \n",
       "1                    293.0  0.508532                       1.0  \n",
       "2                    299.0  0.444816                       1.0  \n",
       "3                    371.0  0.576819                       1.0  \n",
       "4                    474.0  0.860759                       1.0  \n",
       "...                    ...       ...                       ...  \n",
       "11721                497.0  0.012072                       1.0  \n",
       "11722                458.0  0.203057                       1.0  \n",
       "11723                410.0  0.482927                       1.0  \n",
       "11724                746.0  0.454424                       1.0  \n",
       "11725                401.0  0.456359                       1.0  \n",
       "\n",
       "[11726 rows x 5 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84e62716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Convert 'discourse_structure' column to a 2D array\n",
    "discourse_structure_arr = np.array(X['discourse_structure'].tolist())\n",
    "\n",
    "# Convert 'pos_statistics' column to a list of dictionaries\n",
    "pos_statistics_list = X['pos_statistics'].tolist()\n",
    "\n",
    "# Use DictVectorizer to convert the list of dictionaries to a matrix\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "pos_statistics_matrix = vectorizer.fit_transform(pos_statistics_list)\n",
    "\n",
    "# Concatenate the two transformed features\n",
    "X = np.concatenate((discourse_structure_arr, pos_statistics_matrix, data[['avg_sentence_length', 'ttr', 'avg_clauses_per_sentence']]), axis=1)\n",
    "# X = data[['discourse_structure', 'pos_statistics', 'avg_sentence_length', 'ttr', 'avg_clauses_per_sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bd734e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 4.80000000e+01, 4.80000000e+01, ...,\n",
       "        4.80000000e+01, 7.50000000e-01, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.93000000e+02, 2.93000000e+02, ...,\n",
       "        2.93000000e+02, 5.08532423e-01, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.99000000e+02, 2.99000000e+02, ...,\n",
       "        2.99000000e+02, 4.44816054e-01, 1.00000000e+00],\n",
       "       ...,\n",
       "       [1.00000000e+00, 4.10000000e+02, 4.10000000e+02, ...,\n",
       "        4.10000000e+02, 4.82926829e-01, 1.00000000e+00],\n",
       "       [1.00000000e+00, 7.46000000e+02, 7.46000000e+02, ...,\n",
       "        7.46000000e+02, 4.54423592e-01, 1.00000000e+00],\n",
       "       [1.00000000e+00, 4.01000000e+02, 4.01000000e+02, ...,\n",
       "        4.01000000e+02, 4.56359102e-01, 1.00000000e+00]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bd8812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the target variable y\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa437471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 4, ..., 2, 3, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cab8bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e908c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d465c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       220\n",
      "           1       0.47      0.63      0.54       196\n",
      "           2       0.99      1.00      0.99       211\n",
      "           3       0.69      0.67      0.68       220\n",
      "           4       0.62      0.52      0.57       224\n",
      "           5       0.74      0.79      0.76       206\n",
      "           6       0.93      0.78      0.85       240\n",
      "           7       0.61      0.60      0.61       196\n",
      "           8       0.64      0.65      0.64       211\n",
      "           9       1.00      1.00      1.00       205\n",
      "          10       0.99      0.97      0.98       217\n",
      "\n",
      "    accuracy                           0.78      2346\n",
      "   macro avg       0.79      0.78      0.78      2346\n",
      "weighted avg       0.79      0.78      0.78      2346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a027742f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text to predict: abjshksdkjkdgvbsdklhglkslgdfh\n",
      "Discourse Structure: [1, 1, 1.0]\n",
      "POS Statistics: <FreqDist with 1 samples and 1 outcomes>\n",
      "Average Sentence Length: 1.0\n",
      "TTR: 1.0\n",
      "Average Clauses per Sentence: 1.0\n"
     ]
    }
   ],
   "source": [
    "input_text = input(\"Enter text to predict: \")\n",
    "# Sample input text\n",
    "# input_text = \"This is a sample input text. It contains multiple sentences and clauses, demonstrating the features extraction process.\"\n",
    "\n",
    "# Extract discourse structure\n",
    "discourse_structure = extract_discourse_structure(input_text)\n",
    "\n",
    "# Extract POS statistics\n",
    "pos_statistics = extract_pos_statistics(input_text)\n",
    "\n",
    "# Calculate average sentence length\n",
    "avg_sentence_length = calculate_average_sentence_length(input_text)\n",
    "\n",
    "# Calculate type-token ratio (TTR)\n",
    "ttr = calculate_ttr(input_text)\n",
    "\n",
    "# Calculate average clauses per sentence\n",
    "avg_clauses_per_sentence = calculate_average_clauses_per_sentence(input_text)\n",
    "\n",
    "# Print the extracted features\n",
    "print(\"Discourse Structure:\", discourse_structure)\n",
    "print(\"POS Statistics:\", pos_statistics)\n",
    "print(\"Average Sentence Length:\", avg_sentence_length)\n",
    "print(\"TTR:\", ttr)\n",
    "print(\"Average Clauses per Sentence:\", avg_clauses_per_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
