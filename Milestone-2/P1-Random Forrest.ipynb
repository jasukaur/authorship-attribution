{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9642676a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/arsh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/arsh/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Load the data into a pandas dataframe\n",
    "data_path = '/home/arsh/Jasleen/Spring 2023/NLP/MajorFinalProject/data/'\n",
    "df=pd.read_csv(data_path+\"input.csv\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data = df.sample(frac=0.8, random_state=42)\n",
    "test_data = df.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c4136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text data and extract features\n",
    "def preprocess_text(text):\n",
    "    # Perform any text preprocessing tasks here (e.g., tokenization, stop word removal, etc.)\n",
    "    # Tag the words with their respective POS tags\n",
    "    pos_tags = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    # Convert the POS tags into a string of text\n",
    "    pos_text = ' '.join([tag[1] for tag in pos_tags])\n",
    "    # Perform any additional text preprocessing tasks here (e.g., lowercase)\n",
    "    preprocessed_text = pos_text.lower()\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b372c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TfidfVectorizer to extract text features\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_data['text'].apply(preprocess_text))\n",
    "X_test = vectorizer.transform(test_data['text'].apply(preprocess_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e14c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9381x33 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 210316 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f709b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add POS tagging features to the feature matrix\n",
    "pos_tags_train = train_data['text'].apply(preprocess_text)\n",
    "pos_tags_test = test_data['text'].apply(preprocess_text)\n",
    "X_train_pos = vectorizer.fit_transform(pos_tags_train)\n",
    "X_test_pos = vectorizer.transform(pos_tags_test)\n",
    "X_train = np.concatenate((X_train.toarray(), X_train_pos.toarray()), axis=1)\n",
    "X_test = np.concatenate((X_test.toarray(), X_test_pos.toarray()), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abf7fa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6933901918976546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl       0.98      0.98      0.98       216\n",
      "        fair       0.45      0.46      0.45       209\n",
      "         gpt       0.95      0.99      0.97       205\n",
      "        gpt2       0.51      0.54      0.52       201\n",
      "        gpt3       0.43      0.35      0.39       213\n",
      "      grover       0.44      0.59      0.50       205\n",
      "       human       0.68      0.64      0.66       207\n",
      " instructgpt       0.59      0.60      0.60       231\n",
      "        pplm       0.68      0.54      0.60       236\n",
      "         xlm       0.97      1.00      0.98       212\n",
      "       xlnet       0.97      0.97      0.97       210\n",
      "\n",
      "    accuracy                           0.69      2345\n",
      "   macro avg       0.70      0.70      0.69      2345\n",
      "weighted avg       0.70      0.69      0.69      2345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "# Train the random classifier\n",
    "y_train = train_data['class']\n",
    "y_test = test_data['class']\n",
    "clf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b6cf1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.531769722814499\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl       0.84      0.81      0.82       216\n",
      "        fair       0.32      0.22      0.26       209\n",
      "         gpt       0.76      1.00      0.86       205\n",
      "        gpt2       0.27      0.43      0.33       201\n",
      "        gpt3       0.32      0.25      0.28       213\n",
      "      grover       0.33      0.32      0.32       205\n",
      "       human       0.49      0.39      0.44       207\n",
      " instructgpt       0.50      0.55      0.52       231\n",
      "        pplm       0.36      0.25      0.30       236\n",
      "         xlm       0.79      0.90      0.84       212\n",
      "       xlnet       0.75      0.76      0.75       210\n",
      "\n",
      "    accuracy                           0.53      2345\n",
      "   macro avg       0.52      0.53      0.52      2345\n",
      "weighted avg       0.52      0.53      0.52      2345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "y_train = train_data['class']\n",
    "y_test = test_data['class']\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87b0329b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6029850746268657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl       0.90      0.95      0.93       216\n",
      "        fair       0.35      0.44      0.39       209\n",
      "         gpt       0.89      0.99      0.93       205\n",
      "        gpt2       0.42      0.42      0.42       201\n",
      "        gpt3       0.34      0.22      0.27       213\n",
      "      grover       0.35      0.32      0.33       205\n",
      "       human       0.44      0.49      0.46       207\n",
      " instructgpt       0.51      0.62      0.56       231\n",
      "        pplm       0.49      0.35      0.41       236\n",
      "         xlm       0.91      0.98      0.94       212\n",
      "       xlnet       0.93      0.88      0.90       210\n",
      "\n",
      "    accuracy                           0.60      2345\n",
      "   macro avg       0.59      0.60      0.59      2345\n",
      "weighted avg       0.59      0.60      0.59      2345\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsh/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train the Logistic Regression classifier\n",
    "y_train = train_data['class']\n",
    "y_test = test_data['class']\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
